{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 4, Part e: Non-Negative Matrix Factorization DEMO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise illustrates usage of Non-negative Matrix factorization and covers techniques related to sparse matrices and some basic work with Natural Langauge Processing.  We will use NMF to look at the top words for given topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the BBC dataset. These are articles collected from 5 different topics, with the data pre-processed.\n",
    "\n",
    "These data are available in the data folder (or online [here](http://mlg.ucd.ie/files/datasets/bbc.zip?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01)). The data consists of a few files. The steps we'll be following are:\n",
    "\n",
    "*   *bbc.terms* is just a list of words\n",
    "*   *bbc.docs* is a list of artcles listed by topic.\n",
    "\n",
    "At a high level, we're going to\n",
    "\n",
    "1.  Turn the `bbc.mtx` file into a sparse matrix (a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01) format can be useful for matrices with many values that are 0, and save space by storing the position and values of non-zero elements).\n",
    "2.  Decompose that sparse matrix using NMF.\n",
    "3.  Use the resulting components of NMF to analyze the topics that result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This lab has been updated to work in skillsnetwork for your convenience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.mtx') as r:\n",
    "    content = r.readlines()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'1 1 1.0\\n',\n",
       " b'1 7 2.0\\n',\n",
       " b'1 11 1.0\\n',\n",
       " b'1 14 1.0\\n',\n",
       " b'1 15 2.0\\n',\n",
       " b'1 19 2.0\\n',\n",
       " b'1 21 1.0\\n',\n",
       " b'1 29 1.0\\n',\n",
       " b'1 30 1.0\\n',\n",
       " b'1 33 1.0\\n',\n",
       " b'1 35 1.0\\n',\n",
       " b'1 41 1.0\\n',\n",
       " b'1 45 1.0\\n',\n",
       " b'1 47 2.0\\n',\n",
       " b'1 50 1.0\\n',\n",
       " b'1 52 1.0\\n',\n",
       " b'1 53 3.0\\n',\n",
       " b'1 55 1.0\\n',\n",
       " b'1 61 1.0\\n',\n",
       " b'1 62 1.0\\n',\n",
       " b'1 63 1.0\\n',\n",
       " b'1 65 1.0\\n',\n",
       " b'1 69 1.0\\n',\n",
       " b'1 80 1.0\\n',\n",
       " b'1 81 1.0\\n',\n",
       " b'1 86 1.0\\n',\n",
       " b'1 93 1.0\\n',\n",
       " b'1 99 1.0\\n',\n",
       " b'1 100 1.0\\n',\n",
       " b'1 104 1.0\\n',\n",
       " b'1 105 1.0\\n',\n",
       " b'1 106 1.0\\n',\n",
       " b'1 112 1.0\\n',\n",
       " b'1 116 3.0\\n',\n",
       " b'1 117 1.0\\n',\n",
       " b'1 118 2.0\\n',\n",
       " b'1 120 1.0\\n',\n",
       " b'1 121 1.0\\n',\n",
       " b'1 126 1.0\\n',\n",
       " b'1 131 4.0\\n',\n",
       " b'1 133 1.0\\n',\n",
       " b'1 134 3.0\\n',\n",
       " b'1 138 2.0\\n',\n",
       " b'1 140 2.0\\n',\n",
       " b'1 143 1.0\\n',\n",
       " b'1 151 2.0\\n',\n",
       " b'1 152 2.0\\n',\n",
       " b'1 175 1.0\\n',\n",
       " b'1 176 1.0\\n',\n",
       " b'1 177 1.0\\n',\n",
       " b'1 180 1.0\\n',\n",
       " b'1 184 1.0\\n',\n",
       " b'1 189 1.0\\n',\n",
       " b'1 194 1.0\\n',\n",
       " b'1 195 1.0\\n',\n",
       " b'1 198 1.0\\n',\n",
       " b'1 201 1.0\\n',\n",
       " b'1 206 1.0\\n',\n",
       " b'1 207 3.0\\n',\n",
       " b'1 208 1.0\\n',\n",
       " b'1 217 1.0\\n',\n",
       " b'1 219 1.0\\n',\n",
       " b'1 221 1.0\\n',\n",
       " b'1 231 1.0\\n',\n",
       " b'1 241 2.0\\n',\n",
       " b'1 252 1.0\\n',\n",
       " b'1 253 2.0\\n',\n",
       " b'1 255 2.0\\n',\n",
       " b'1 263 1.0\\n',\n",
       " b'1 273 1.0\\n',\n",
       " b'1 275 1.0\\n',\n",
       " b'1 279 2.0\\n',\n",
       " b'1 281 1.0\\n',\n",
       " b'1 286 1.0\\n',\n",
       " b'1 290 1.0\\n',\n",
       " b'1 292 1.0\\n',\n",
       " b'1 296 4.0\\n',\n",
       " b'1 299 2.0\\n',\n",
       " b'1 301 1.0\\n',\n",
       " b'1 303 1.0\\n',\n",
       " b'1 307 2.0\\n',\n",
       " b'1 310 1.0\\n',\n",
       " b'1 317 1.0\\n',\n",
       " b'1 323 1.0\\n',\n",
       " b'1 324 1.0\\n',\n",
       " b'1 328 1.0\\n',\n",
       " b'1 329 2.0\\n',\n",
       " b'1 334 1.0\\n',\n",
       " b'1 348 1.0\\n',\n",
       " b'1 357 1.0\\n',\n",
       " b'1 359 1.0\\n',\n",
       " b'1 360 1.0\\n',\n",
       " b'1 362 1.0\\n',\n",
       " b'1 363 1.0\\n',\n",
       " b'1 366 1.0\\n',\n",
       " b'1 367 1.0\\n',\n",
       " b'1 373 1.0\\n',\n",
       " b'1 374 1.0\\n',\n",
       " b'1 376 1.0\\n',\n",
       " b'1 377 1.0\\n',\n",
       " b'1 379 1.0\\n',\n",
       " b'1 380 2.0\\n',\n",
       " b'1 386 3.0\\n',\n",
       " b'1 387 2.0\\n',\n",
       " b'1 392 1.0\\n',\n",
       " b'1 400 1.0\\n',\n",
       " b'1 401 4.0\\n',\n",
       " b'1 402 1.0\\n',\n",
       " b'1 403 1.0\\n',\n",
       " b'1 406 1.0\\n',\n",
       " b'1 414 2.0\\n',\n",
       " b'1 416 1.0\\n',\n",
       " b'1 421 1.0\\n',\n",
       " b'1 425 1.0\\n',\n",
       " b'1 433 1.0\\n',\n",
       " b'1 434 1.0\\n',\n",
       " b'1 438 1.0\\n',\n",
       " b'1 443 1.0\\n',\n",
       " b'1 446 1.0\\n',\n",
       " b'1 448 1.0\\n',\n",
       " b'1 449 1.0\\n',\n",
       " b'1 450 1.0\\n',\n",
       " b'1 453 2.0\\n',\n",
       " b'1 456 1.0\\n',\n",
       " b'1 462 1.0\\n',\n",
       " b'1 463 1.0\\n',\n",
       " b'1 466 1.0\\n',\n",
       " b'1 469 1.0\\n',\n",
       " b'1 471 2.0\\n',\n",
       " b'1 479 1.0\\n',\n",
       " b'1 493 1.0\\n',\n",
       " b'1 501 3.0\\n',\n",
       " b'1 505 1.0\\n',\n",
       " b'1 525 1.0\\n',\n",
       " b'1 535 1.0\\n',\n",
       " b'1 536 2.0\\n',\n",
       " b'1 537 1.0\\n',\n",
       " b'1 540 2.0\\n',\n",
       " b'1 546 1.0\\n',\n",
       " b'1 549 1.0\\n',\n",
       " b'1 550 1.0\\n',\n",
       " b'1 551 1.0\\n',\n",
       " b'1 553 1.0\\n',\n",
       " b'1 566 1.0\\n',\n",
       " b'1 574 2.0\\n',\n",
       " b'1 575 1.0\\n',\n",
       " b'1 576 1.0\\n',\n",
       " b'1 582 1.0\\n',\n",
       " b'1 585 1.0\\n',\n",
       " b'1 590 1.0\\n',\n",
       " b'1 591 1.0\\n',\n",
       " b'1 592 1.0\\n',\n",
       " b'1 597 1.0\\n',\n",
       " b'1 600 1.0\\n',\n",
       " b'1 603 3.0\\n',\n",
       " b'1 604 1.0\\n',\n",
       " b'1 627 1.0\\n',\n",
       " b'1 628 2.0\\n',\n",
       " b'1 631 1.0\\n',\n",
       " b'1 632 1.0\\n',\n",
       " b'1 638 1.0\\n',\n",
       " b'1 640 1.0\\n',\n",
       " b'1 641 1.0\\n',\n",
       " b'1 644 2.0\\n',\n",
       " b'1 647 1.0\\n',\n",
       " b'1 651 1.0\\n',\n",
       " b'1 671 1.0\\n',\n",
       " b'1 683 1.0\\n',\n",
       " b'1 684 1.0\\n',\n",
       " b'1 688 1.0\\n',\n",
       " b'1 691 2.0\\n',\n",
       " b'1 692 2.0\\n',\n",
       " b'1 693 1.0\\n',\n",
       " b'1 694 1.0\\n',\n",
       " b'1 695 1.0\\n',\n",
       " b'1 696 1.0\\n',\n",
       " b'1 703 2.0\\n',\n",
       " b'1 713 2.0\\n',\n",
       " b'1 721 1.0\\n',\n",
       " b'1 731 3.0\\n',\n",
       " b'1 733 2.0\\n',\n",
       " b'1 741 1.0\\n',\n",
       " b'1 742 1.0\\n',\n",
       " b'1 755 2.0\\n',\n",
       " b'1 762 1.0\\n',\n",
       " b'1 763 2.0\\n',\n",
       " b'1 765 2.0\\n',\n",
       " b'1 772 1.0\\n',\n",
       " b'1 776 1.0\\n',\n",
       " b'1 779 2.0\\n',\n",
       " b'1 781 2.0\\n',\n",
       " b'1 785 1.0\\n',\n",
       " b'1 792 1.0\\n',\n",
       " b'1 794 1.0\\n',\n",
       " b'1 799 3.0\\n',\n",
       " b'1 801 1.0\\n',\n",
       " b'1 802 1.0\\n',\n",
       " b'1 803 2.0\\n',\n",
       " b'1 804 1.0\\n',\n",
       " b'1 806 1.0\\n',\n",
       " b'1 809 1.0\\n',\n",
       " b'1 813 1.0\\n',\n",
       " b'1 816 1.0\\n',\n",
       " b'1 820 1.0\\n',\n",
       " b'1 821 1.0\\n',\n",
       " b'1 831 1.0\\n',\n",
       " b'1 839 1.0\\n',\n",
       " b'1 840 1.0\\n',\n",
       " b'1 847 1.0\\n',\n",
       " b'1 855 1.0\\n',\n",
       " b'1 862 3.0\\n',\n",
       " b'1 866 1.0\\n',\n",
       " b'1 868 2.0\\n',\n",
       " b'1 875 1.0\\n',\n",
       " b'1 877 2.0\\n',\n",
       " b'1 881 1.0\\n',\n",
       " b'1 883 1.0\\n',\n",
       " b'1 891 1.0\\n',\n",
       " b'1 899 1.0\\n',\n",
       " b'1 901 1.0\\n',\n",
       " b'1 902 1.0\\n',\n",
       " b'1 904 1.0\\n',\n",
       " b'1 907 1.0\\n',\n",
       " b'1 908 1.0\\n',\n",
       " b'1 910 1.0\\n',\n",
       " b'1 912 2.0\\n',\n",
       " b'1 915 3.0\\n',\n",
       " b'1 918 2.0\\n',\n",
       " b'1 919 1.0\\n',\n",
       " b'1 923 1.0\\n',\n",
       " b'1 929 1.0\\n',\n",
       " b'1 930 1.0\\n',\n",
       " b'1 935 1.0\\n',\n",
       " b'1 937 1.0\\n',\n",
       " b'1 944 2.0\\n',\n",
       " b'1 946 2.0\\n',\n",
       " b'1 952 2.0\\n',\n",
       " b'1 956 1.0\\n',\n",
       " b'1 957 1.0\\n',\n",
       " b'1 958 1.0\\n',\n",
       " b'1 959 1.0\\n',\n",
       " b'1 961 1.0\\n',\n",
       " b'1 963 1.0\\n',\n",
       " b'1 965 1.0\\n',\n",
       " b'1 967 1.0\\n',\n",
       " b'1 969 2.0\\n',\n",
       " b'1 972 1.0\\n',\n",
       " b'1 976 2.0\\n',\n",
       " b'1 978 1.0\\n',\n",
       " b'1 979 1.0\\n',\n",
       " b'1 982 1.0\\n',\n",
       " b'1 984 1.0\\n',\n",
       " b'1 985 2.0\\n',\n",
       " b'1 990 1.0\\n',\n",
       " b'1 993 1.0\\n',\n",
       " b'1 996 1.0\\n',\n",
       " b'1 997 1.0\\n',\n",
       " b'1 1000 2.0\\n',\n",
       " b'1 1001 3.0\\n',\n",
       " b'1 1005 1.0\\n',\n",
       " b'1 1006 1.0\\n',\n",
       " b'1 1014 1.0\\n',\n",
       " b'1 1016 2.0\\n',\n",
       " b'1 1017 1.0\\n',\n",
       " b'1 1020 1.0\\n',\n",
       " b'1 1021 1.0\\n',\n",
       " b'1 1023 2.0\\n',\n",
       " b'1 1025 1.0\\n',\n",
       " b'1 1026 1.0\\n',\n",
       " b'1 1031 1.0\\n',\n",
       " b'1 1034 1.0\\n',\n",
       " b'1 1037 1.0\\n',\n",
       " b'1 1038 3.0\\n',\n",
       " b'1 1039 2.0\\n',\n",
       " b'1 1041 1.0\\n',\n",
       " b'1 1043 1.0\\n',\n",
       " b'1 1045 1.0\\n',\n",
       " b'1 1048 1.0\\n',\n",
       " b'1 1050 1.0\\n',\n",
       " b'1 1051 1.0\\n',\n",
       " b'1 1054 1.0\\n',\n",
       " b'1 1056 1.0\\n',\n",
       " b'1 1057 2.0\\n',\n",
       " b'1 1058 1.0\\n',\n",
       " b'1 1059 2.0\\n',\n",
       " b'1 1061 1.0\\n',\n",
       " b'1 1070 1.0\\n',\n",
       " b'1 1077 1.0\\n',\n",
       " b'1 1080 1.0\\n',\n",
       " b'1 1083 1.0\\n',\n",
       " b'1 1085 4.0\\n',\n",
       " b'1 1087 1.0\\n',\n",
       " b'1 1088 2.0\\n',\n",
       " b'1 1091 2.0\\n',\n",
       " b'1 1096 1.0\\n',\n",
       " b'1 1097 1.0\\n',\n",
       " b'1 1098 1.0\\n',\n",
       " b'1 1101 1.0\\n',\n",
       " b'1 1105 3.0\\n',\n",
       " b'1 1108 2.0\\n',\n",
       " b'1 1111 1.0\\n',\n",
       " b'1 1113 1.0\\n',\n",
       " b'1 1119 1.0\\n',\n",
       " b'1 1124 1.0\\n',\n",
       " b'1 1126 1.0\\n',\n",
       " b'1 1134 2.0\\n',\n",
       " b'1 1140 1.0\\n',\n",
       " b'1 1142 2.0\\n',\n",
       " b'1 1147 2.0\\n',\n",
       " b'1 1148 2.0\\n',\n",
       " b'1 1151 1.0\\n',\n",
       " b'1 1153 1.0\\n',\n",
       " b'1 1162 1.0\\n',\n",
       " b'1 1164 1.0\\n',\n",
       " b'1 1166 1.0\\n',\n",
       " b'1 1167 2.0\\n',\n",
       " b'1 1171 1.0\\n',\n",
       " b'1 1172 1.0\\n',\n",
       " b'1 1177 1.0\\n',\n",
       " b'1 1178 1.0\\n',\n",
       " b'1 1181 1.0\\n',\n",
       " b'1 1182 1.0\\n',\n",
       " b'1 1190 2.0\\n',\n",
       " b'1 1192 1.0\\n',\n",
       " b'1 1196 1.0\\n',\n",
       " b'1 1198 1.0\\n',\n",
       " b'1 1199 1.0\\n',\n",
       " b'1 1200 1.0\\n',\n",
       " b'1 1202 1.0\\n',\n",
       " b'1 1203 2.0\\n',\n",
       " b'1 1207 1.0\\n',\n",
       " b'1 1208 1.0\\n',\n",
       " b'1 1210 1.0\\n',\n",
       " b'1 1211 4.0\\n',\n",
       " b'1 1212 1.0\\n',\n",
       " b'1 1215 1.0\\n',\n",
       " b'1 1217 1.0\\n',\n",
       " b'1 1221 1.0\\n',\n",
       " b'1 1223 2.0\\n',\n",
       " b'1 1224 1.0\\n',\n",
       " b'1 1225 2.0\\n',\n",
       " b'1 1228 2.0\\n',\n",
       " b'1 1232 2.0\\n',\n",
       " b'1 1234 1.0\\n',\n",
       " b'1 1235 1.0\\n',\n",
       " b'1 1237 1.0\\n',\n",
       " b'1 1242 2.0\\n',\n",
       " b'1 1249 1.0\\n',\n",
       " b'1 1253 1.0\\n',\n",
       " b'1 1254 2.0\\n',\n",
       " b'1 1255 1.0\\n',\n",
       " b'1 1257 1.0\\n',\n",
       " b'1 1259 3.0\\n',\n",
       " b'1 1260 1.0\\n',\n",
       " b'1 1262 2.0\\n',\n",
       " b'1 1263 1.0\\n',\n",
       " b'1 1271 2.0\\n',\n",
       " b'1 1279 1.0\\n',\n",
       " b'1 1286 1.0\\n',\n",
       " b'1 1288 1.0\\n',\n",
       " b'1 1291 1.0\\n',\n",
       " b'1 1298 1.0\\n',\n",
       " b'1 1299 1.0\\n',\n",
       " b'1 1307 1.0\\n',\n",
       " b'1 1309 1.0\\n',\n",
       " b'1 1310 2.0\\n',\n",
       " b'1 1311 1.0\\n',\n",
       " b'1 1312 1.0\\n',\n",
       " b'1 1321 1.0\\n',\n",
       " b'1 1326 1.0\\n',\n",
       " b'1 1328 1.0\\n',\n",
       " b'1 1330 1.0\\n',\n",
       " b'1 1346 1.0\\n',\n",
       " b'1 1347 1.0\\n',\n",
       " b'1 1357 1.0\\n',\n",
       " b'1 1359 1.0\\n',\n",
       " b'1 1361 1.0\\n',\n",
       " b'1 1362 2.0\\n',\n",
       " b'1 1365 1.0\\n',\n",
       " b'1 1376 1.0\\n',\n",
       " b'1 1379 1.0\\n',\n",
       " b'1 1380 1.0\\n',\n",
       " b'1 1381 2.0\\n',\n",
       " b'1 1392 1.0\\n',\n",
       " b'1 1393 2.0\\n',\n",
       " b'1 1397 1.0\\n',\n",
       " b'1 1398 1.0\\n',\n",
       " b'1 1401 2.0\\n',\n",
       " b'1 1403 1.0\\n',\n",
       " b'1 1405 1.0\\n',\n",
       " b'1 1410 1.0\\n',\n",
       " b'1 1411 1.0\\n',\n",
       " b'1 1412 1.0\\n',\n",
       " b'1 1413 1.0\\n',\n",
       " b'1 1415 1.0\\n',\n",
       " b'1 1425 1.0\\n',\n",
       " b'1 1426 1.0\\n',\n",
       " b'1 1427 1.0\\n',\n",
       " b'1 1434 1.0\\n',\n",
       " b'1 1437 1.0\\n',\n",
       " b'1 1439 2.0\\n',\n",
       " b'1 1450 1.0\\n',\n",
       " b'1 1452 1.0\\n',\n",
       " b'1 1453 2.0\\n',\n",
       " b'1 1454 1.0\\n',\n",
       " b'1 1455 1.0\\n',\n",
       " b'1 1456 1.0\\n',\n",
       " b'1 1457 1.0\\n',\n",
       " b'1 1458 2.0\\n',\n",
       " b'1 1463 1.0\\n',\n",
       " b'1 1464 1.0\\n',\n",
       " b'1 1466 1.0\\n',\n",
       " b'1 1467 2.0\\n',\n",
       " b'1 1468 1.0\\n',\n",
       " b'1 1470 1.0\\n',\n",
       " b'1 1473 1.0\\n',\n",
       " b'1 1479 1.0\\n',\n",
       " b'1 1480 1.0\\n',\n",
       " b'1 1485 2.0\\n',\n",
       " b'1 1488 1.0\\n',\n",
       " b'1 1489 1.0\\n',\n",
       " b'1 1490 1.0\\n',\n",
       " b'1 1491 2.0\\n',\n",
       " b'1 1496 1.0\\n',\n",
       " b'1 1499 2.0\\n',\n",
       " b'1 1501 1.0\\n',\n",
       " b'1 1502 1.0\\n',\n",
       " b'1 1506 1.0\\n',\n",
       " b'1 1507 1.0\\n',\n",
       " b'1 1511 1.0\\n',\n",
       " b'1 1512 1.0\\n',\n",
       " b'1 1514 1.0\\n',\n",
       " b'1 1515 1.0\\n',\n",
       " b'1 1516 1.0\\n',\n",
       " b'1 1519 1.0\\n',\n",
       " b'1 1520 1.0\\n',\n",
       " b'1 1521 1.0\\n',\n",
       " b'1 1522 1.0\\n',\n",
       " b'1 1524 2.0\\n',\n",
       " b'1 1526 1.0\\n',\n",
       " b'1 1529 2.0\\n',\n",
       " b'1 1535 1.0\\n',\n",
       " b'1 1536 2.0\\n',\n",
       " b'1 1542 1.0\\n',\n",
       " b'1 1544 1.0\\n',\n",
       " b'1 1548 3.0\\n',\n",
       " b'1 1549 1.0\\n',\n",
       " b'1 1551 1.0\\n',\n",
       " b'1 1555 1.0\\n',\n",
       " b'1 1556 1.0\\n',\n",
       " b'1 1557 1.0\\n',\n",
       " b'1 1560 2.0\\n',\n",
       " b'1 1561 2.0\\n',\n",
       " b'1 1563 2.0\\n',\n",
       " b'1 1564 1.0\\n',\n",
       " b'1 1566 1.0\\n',\n",
       " b'1 1567 2.0\\n',\n",
       " b'1 1576 1.0\\n',\n",
       " b'1 1578 1.0\\n',\n",
       " b'1 1579 1.0\\n',\n",
       " b'1 1580 2.0\\n',\n",
       " b'1 1582 1.0\\n',\n",
       " b'1 1583 1.0\\n',\n",
       " b'1 1586 1.0\\n',\n",
       " b'1 1587 1.0\\n',\n",
       " b'1 1590 1.0\\n',\n",
       " b'1 1591 1.0\\n',\n",
       " b'1 1593 1.0\\n',\n",
       " b'1 1594 1.0\\n',\n",
       " b'1 1596 1.0\\n',\n",
       " b'1 1597 2.0\\n',\n",
       " b'1 1601 1.0\\n',\n",
       " b'1 1604 1.0\\n',\n",
       " b'1 1607 4.0\\n',\n",
       " b'1 1609 1.0\\n',\n",
       " b'1 1613 1.0\\n',\n",
       " b'1 1616 1.0\\n',\n",
       " b'1 1624 2.0\\n',\n",
       " b'1 1625 2.0\\n',\n",
       " b'1 1626 2.0\\n',\n",
       " b'1 1628 1.0\\n',\n",
       " b'1 1635 1.0\\n',\n",
       " b'1 1640 2.0\\n',\n",
       " b'1 1641 1.0\\n',\n",
       " b'1 1642 1.0\\n',\n",
       " b'1 1643 3.0\\n',\n",
       " b'1 1644 2.0\\n',\n",
       " b'1 1646 1.0\\n',\n",
       " b'1 1647 1.0\\n',\n",
       " b'1 1649 1.0\\n',\n",
       " b'1 1651 2.0\\n',\n",
       " b'1 1653 1.0\\n',\n",
       " b'1 1654 1.0\\n',\n",
       " b'1 1660 2.0\\n',\n",
       " b'1 1665 2.0\\n',\n",
       " b'1 1666 1.0\\n',\n",
       " b'1 1671 2.0\\n',\n",
       " b'1 1677 1.0\\n',\n",
       " b'1 1679 1.0\\n',\n",
       " b'1 1685 2.0\\n',\n",
       " b'1 1686 1.0\\n',\n",
       " b'1 1687 1.0\\n',\n",
       " b'1 1695 2.0\\n',\n",
       " b'1 1697 1.0\\n',\n",
       " b'1 1698 1.0\\n',\n",
       " b'1 1700 1.0\\n',\n",
       " b'1 1704 1.0\\n',\n",
       " b'1 1706 1.0\\n',\n",
       " b'1 1722 1.0\\n',\n",
       " b'1 1724 1.0\\n',\n",
       " b'1 1725 1.0\\n',\n",
       " b'1 1726 1.0\\n',\n",
       " b'1 1727 1.0\\n',\n",
       " b'1 1728 2.0\\n',\n",
       " b'1 1729 2.0\\n',\n",
       " b'1 1733 1.0\\n',\n",
       " b'1 1738 1.0\\n',\n",
       " b'1 1740 1.0\\n',\n",
       " b'1 1745 2.0\\n',\n",
       " b'1 1746 1.0\\n',\n",
       " b'1 1751 2.0\\n',\n",
       " b'1 1758 1.0\\n',\n",
       " b'1 1765 1.0\\n',\n",
       " b'1 1767 1.0\\n',\n",
       " b'1 1775 1.0\\n',\n",
       " b'1 1777 1.0\\n',\n",
       " b'1 1785 1.0\\n',\n",
       " b'1 1787 1.0\\n',\n",
       " b'1 1788 1.0\\n',\n",
       " b'1 1793 1.0\\n',\n",
       " b'1 1795 1.0\\n',\n",
       " b'1 1799 1.0\\n',\n",
       " b'1 1813 2.0\\n',\n",
       " b'1 1814 1.0\\n',\n",
       " b'1 1816 1.0\\n',\n",
       " b'1 1822 1.0\\n',\n",
       " b'1 1829 1.0\\n',\n",
       " b'1 1833 1.0\\n',\n",
       " b'1 1839 1.0\\n',\n",
       " b'1 1840 2.0\\n',\n",
       " b'1 1841 1.0\\n',\n",
       " b'1 1842 1.0\\n',\n",
       " b'1 1848 1.0\\n',\n",
       " b'1 1850 1.0\\n',\n",
       " b'1 1853 1.0\\n',\n",
       " b'1 1855 1.0\\n',\n",
       " b'1 1856 1.0\\n',\n",
       " b'1 1862 1.0\\n',\n",
       " b'1 1864 2.0\\n',\n",
       " b'1 1865 3.0\\n',\n",
       " b'1 1870 1.0\\n',\n",
       " b'1 1871 1.0\\n',\n",
       " b'1 1873 1.0\\n',\n",
       " b'1 1876 1.0\\n',\n",
       " b'1 1882 1.0\\n',\n",
       " b'1 1886 1.0\\n',\n",
       " b'1 1888 1.0\\n',\n",
       " b'1 1891 1.0\\n',\n",
       " b'1 1897 1.0\\n',\n",
       " b'1 1900 1.0\\n',\n",
       " b'1 1903 1.0\\n',\n",
       " b'1 1904 1.0\\n',\n",
       " b'1 1905 1.0\\n',\n",
       " b'1 1906 1.0\\n',\n",
       " b'1 1908 1.0\\n',\n",
       " b'1 1912 3.0\\n',\n",
       " b'1 1913 1.0\\n',\n",
       " b'1 1915 1.0\\n',\n",
       " b'1 1916 1.0\\n',\n",
       " b'1 1918 1.0\\n',\n",
       " b'1 1920 1.0\\n',\n",
       " b'1 1926 2.0\\n',\n",
       " b'1 1937 2.0\\n',\n",
       " b'1 1945 1.0\\n',\n",
       " b'1 1946 1.0\\n',\n",
       " b'1 1948 2.0\\n',\n",
       " b'1 1954 1.0\\n',\n",
       " b'1 1957 1.0\\n',\n",
       " b'1 1960 1.0\\n',\n",
       " b'1 1962 1.0\\n',\n",
       " b'1 1963 1.0\\n',\n",
       " b'1 1966 1.0\\n',\n",
       " b'1 1973 1.0\\n',\n",
       " b'1 1975 1.0\\n',\n",
       " b'1 1979 4.0\\n',\n",
       " b'1 1980 1.0\\n',\n",
       " b'1 1981 1.0\\n',\n",
       " b'1 1986 1.0\\n',\n",
       " b'1 1992 2.0\\n',\n",
       " b'1 2002 1.0\\n',\n",
       " b'1 2004 1.0\\n',\n",
       " b'1 2012 2.0\\n',\n",
       " b'1 2015 1.0\\n',\n",
       " b'1 2018 1.0\\n',\n",
       " b'1 2019 1.0\\n',\n",
       " b'1 2024 1.0\\n',\n",
       " b'1 2030 5.0\\n',\n",
       " b'1 2033 2.0\\n',\n",
       " b'1 2037 2.0\\n',\n",
       " b'1 2038 1.0\\n',\n",
       " b'1 2040 1.0\\n',\n",
       " b'1 2044 1.0\\n',\n",
       " b'1 2045 1.0\\n',\n",
       " b'1 2046 1.0\\n',\n",
       " b'1 2052 1.0\\n',\n",
       " b'1 2059 1.0\\n',\n",
       " b'1 2065 1.0\\n',\n",
       " b'1 2066 1.0\\n',\n",
       " b'1 2067 1.0\\n',\n",
       " b'1 2078 1.0\\n',\n",
       " b'1 2082 1.0\\n',\n",
       " b'1 2083 1.0\\n',\n",
       " b'1 2084 1.0\\n',\n",
       " b'1 2085 4.0\\n',\n",
       " b'1 2091 1.0\\n',\n",
       " b'1 2092 1.0\\n',\n",
       " b'1 2094 1.0\\n',\n",
       " b'1 2102 2.0\\n',\n",
       " b'1 2103 1.0\\n',\n",
       " b'1 2104 2.0\\n',\n",
       " b'1 2112 1.0\\n',\n",
       " b'1 2117 1.0\\n',\n",
       " b'1 2118 4.0\\n',\n",
       " b'1 2119 1.0\\n',\n",
       " b'1 2121 1.0\\n',\n",
       " b'1 2123 1.0\\n',\n",
       " b'1 2124 1.0\\n',\n",
       " b'1 2125 4.0\\n',\n",
       " b'1 2126 1.0\\n',\n",
       " b'1 2129 1.0\\n',\n",
       " b'1 2134 1.0\\n',\n",
       " b'1 2137 1.0\\n',\n",
       " b'1 2140 1.0\\n',\n",
       " b'1 2142 1.0\\n',\n",
       " b'1 2151 1.0\\n',\n",
       " b'1 2156 2.0\\n',\n",
       " b'1 2159 1.0\\n',\n",
       " b'1 2160 1.0\\n',\n",
       " b'1 2161 1.0\\n',\n",
       " b'1 2162 1.0\\n',\n",
       " b'1 2164 1.0\\n',\n",
       " b'1 2178 2.0\\n',\n",
       " b'1 2184 1.0\\n',\n",
       " b'1 2185 1.0\\n',\n",
       " b'1 2188 1.0\\n',\n",
       " b'1 2195 2.0\\n',\n",
       " b'1 2197 1.0\\n',\n",
       " b'1 2200 3.0\\n',\n",
       " b'1 2201 1.0\\n',\n",
       " b'1 2203 1.0\\n',\n",
       " b'1 2206 1.0\\n',\n",
       " b'1 2208 1.0\\n',\n",
       " b'1 2217 1.0\\n',\n",
       " b'1 2218 2.0\\n',\n",
       " b'2 1 5.0\\n',\n",
       " b'2 3 4.0\\n',\n",
       " b'2 4 1.0\\n',\n",
       " b'2 11 1.0\\n',\n",
       " b'2 13 5.0\\n',\n",
       " b'2 14 1.0\\n',\n",
       " b'2 16 1.0\\n',\n",
       " b'2 25 1.0\\n',\n",
       " b'2 26 1.0\\n',\n",
       " b'2 27 1.0\\n',\n",
       " b'2 38 3.0\\n',\n",
       " b'2 39 2.0\\n',\n",
       " b'2 40 5.0\\n',\n",
       " b'2 49 1.0\\n',\n",
       " b'2 50 6.0\\n',\n",
       " b'2 51 2.0\\n',\n",
       " b'2 53 1.0\\n',\n",
       " b'2 54 2.0\\n',\n",
       " b'2 56 9.0\\n',\n",
       " b'2 63 15.0\\n',\n",
       " b'2 67 1.0\\n',\n",
       " b'2 72 1.0\\n',\n",
       " b'2 77 1.0\\n',\n",
       " b'2 83 1.0\\n',\n",
       " b'2 88 2.0\\n',\n",
       " b'2 90 2.0\\n',\n",
       " b'2 91 2.0\\n',\n",
       " b'2 95 6.0\\n',\n",
       " b'2 99 19.0\\n',\n",
       " b'2 107 1.0\\n',\n",
       " b'2 111 5.0\\n',\n",
       " b'2 112 2.0\\n',\n",
       " b'2 115 3.0\\n',\n",
       " b'2 117 3.0\\n',\n",
       " b'2 118 4.0\\n',\n",
       " b'2 122 1.0\\n',\n",
       " b'2 127 1.0\\n',\n",
       " b'2 128 1.0\\n',\n",
       " b'2 130 1.0\\n',\n",
       " b'2 132 6.0\\n',\n",
       " b'2 136 1.0\\n',\n",
       " b'2 140 2.0\\n',\n",
       " b'2 143 6.0\\n',\n",
       " b'2 150 1.0\\n',\n",
       " b'2 155 3.0\\n',\n",
       " b'2 156 2.0\\n',\n",
       " b'2 157 1.0\\n',\n",
       " b'2 164 1.0\\n',\n",
       " b'2 170 2.0\\n',\n",
       " b'2 171 1.0\\n',\n",
       " b'2 173 7.0\\n',\n",
       " b'2 174 1.0\\n',\n",
       " b'2 175 3.0\\n',\n",
       " b'2 177 1.0\\n',\n",
       " b'2 181 1.0\\n',\n",
       " b'2 189 2.0\\n',\n",
       " b'2 190 1.0\\n',\n",
       " b'2 191 2.0\\n',\n",
       " b'2 192 3.0\\n',\n",
       " b'2 193 1.0\\n',\n",
       " b'2 197 4.0\\n',\n",
       " b'2 201 2.0\\n',\n",
       " b'2 207 6.0\\n',\n",
       " b'2 210 1.0\\n',\n",
       " b'2 212 1.0\\n',\n",
       " b'2 216 3.0\\n',\n",
       " b'2 217 2.0\\n',\n",
       " b'2 218 1.0\\n',\n",
       " b'2 223 4.0\\n',\n",
       " b'2 225 6.0\\n',\n",
       " b'2 226 1.0\\n',\n",
       " b'2 230 5.0\\n',\n",
       " b'2 233 1.0\\n',\n",
       " b'2 239 1.0\\n',\n",
       " b'2 247 6.0\\n',\n",
       " b'2 248 3.0\\n',\n",
       " b'2 250 2.0\\n',\n",
       " b'2 262 1.0\\n',\n",
       " b'2 263 1.0\\n',\n",
       " b'2 267 3.0\\n',\n",
       " b'2 269 1.0\\n',\n",
       " b'2 271 1.0\\n',\n",
       " b'2 274 1.0\\n',\n",
       " b'2 276 2.0\\n',\n",
       " b'2 278 1.0\\n',\n",
       " b'2 286 1.0\\n',\n",
       " b'2 287 1.0\\n',\n",
       " b'2 288 2.0\\n',\n",
       " b'2 289 1.0\\n',\n",
       " b'2 290 2.0\\n',\n",
       " b'2 293 1.0\\n',\n",
       " b'2 295 1.0\\n',\n",
       " b'2 299 2.0\\n',\n",
       " b'2 302 2.0\\n',\n",
       " b'2 306 8.0\\n',\n",
       " b'2 312 1.0\\n',\n",
       " b'2 314 4.0\\n',\n",
       " b'2 317 7.0\\n',\n",
       " b'2 318 2.0\\n',\n",
       " b'2 323 1.0\\n',\n",
       " b'2 324 5.0\\n',\n",
       " b'2 325 1.0\\n',\n",
       " b'2 329 5.0\\n',\n",
       " b'2 332 1.0\\n',\n",
       " b'2 340 1.0\\n',\n",
       " b'2 341 2.0\\n',\n",
       " b'2 344 1.0\\n',\n",
       " b'2 358 2.0\\n',\n",
       " b'2 359 2.0\\n',\n",
       " b'2 361 5.0\\n',\n",
       " b'2 365 3.0\\n',\n",
       " b'2 373 1.0\\n',\n",
       " b'2 384 11.0\\n',\n",
       " b'2 385 1.0\\n',\n",
       " b'2 386 1.0\\n',\n",
       " b'2 389 1.0\\n',\n",
       " b'2 390 9.0\\n',\n",
       " b'2 391 1.0\\n',\n",
       " b'2 393 3.0\\n',\n",
       " b'2 406 15.0\\n',\n",
       " b'2 408 4.0\\n',\n",
       " b'2 409 1.0\\n',\n",
       " b'2 410 7.0\\n',\n",
       " b'2 426 3.0\\n',\n",
       " b'2 430 2.0\\n',\n",
       " b'2 431 2.0\\n',\n",
       " b'2 436 1.0\\n',\n",
       " b'2 438 2.0\\n',\n",
       " b'2 439 1.0\\n',\n",
       " b'2 440 1.0\\n',\n",
       " b'2 441 1.0\\n',\n",
       " b'2 444 2.0\\n',\n",
       " b'2 450 15.0\\n',\n",
       " b'2 451 1.0\\n',\n",
       " b'2 452 1.0\\n',\n",
       " b'2 453 1.0\\n',\n",
       " b'2 456 1.0\\n',\n",
       " b'2 462 1.0\\n',\n",
       " b'2 463 1.0\\n',\n",
       " b'2 464 1.0\\n',\n",
       " b'2 475 2.0\\n',\n",
       " b'2 476 1.0\\n',\n",
       " b'2 479 3.0\\n',\n",
       " b'2 480 1.0\\n',\n",
       " b'2 481 6.0\\n',\n",
       " b'2 483 2.0\\n',\n",
       " b'2 489 2.0\\n',\n",
       " b'2 493 1.0\\n',\n",
       " b'2 500 2.0\\n',\n",
       " b'2 503 3.0\\n',\n",
       " b'2 504 1.0\\n',\n",
       " b'2 507 1.0\\n',\n",
       " b'2 510 1.0\\n',\n",
       " b'2 514 2.0\\n',\n",
       " b'2 521 7.0\\n',\n",
       " b'2 528 5.0\\n',\n",
       " b'2 534 2.0\\n',\n",
       " b'2 551 1.0\\n',\n",
       " b'2 556 2.0\\n',\n",
       " b'2 559 1.0\\n',\n",
       " b'2 564 1.0\\n',\n",
       " b'2 576 3.0\\n',\n",
       " b'2 583 1.0\\n',\n",
       " b'2 584 1.0\\n',\n",
       " b'2 593 1.0\\n',\n",
       " b'2 598 1.0\\n',\n",
       " b'2 613 11.0\\n',\n",
       " b'2 623 1.0\\n',\n",
       " b'2 632 1.0\\n',\n",
       " b'2 637 11.0\\n',\n",
       " b'2 640 1.0\\n',\n",
       " b'2 641 1.0\\n',\n",
       " b'2 647 1.0\\n',\n",
       " b'2 650 2.0\\n',\n",
       " b'2 652 1.0\\n',\n",
       " b'2 653 1.0\\n',\n",
       " b'2 656 1.0\\n',\n",
       " b'2 658 1.0\\n',\n",
       " b'2 661 2.0\\n',\n",
       " b'2 662 1.0\\n',\n",
       " b'2 665 2.0\\n',\n",
       " b'2 669 1.0\\n',\n",
       " b'2 670 2.0\\n',\n",
       " b'2 672 2.0\\n',\n",
       " b'2 673 1.0\\n',\n",
       " b'2 674 2.0\\n',\n",
       " b'2 689 1.0\\n',\n",
       " b'2 691 5.0\\n',\n",
       " b'2 692 1.0\\n',\n",
       " b'2 716 2.0\\n',\n",
       " b'2 726 1.0\\n',\n",
       " b'2 739 1.0\\n',\n",
       " b'2 746 1.0\\n',\n",
       " b'2 749 1.0\\n',\n",
       " b'2 750 3.0\\n',\n",
       " b'2 760 2.0\\n',\n",
       " b'2 763 1.0\\n',\n",
       " b'2 772 1.0\\n',\n",
       " b'2 776 3.0\\n',\n",
       " b'2 780 2.0\\n',\n",
       " b'2 781 3.0\\n',\n",
       " b'2 788 1.0\\n',\n",
       " b'2 791 2.0\\n',\n",
       " b'2 793 1.0\\n',\n",
       " b'2 794 2.0\\n',\n",
       " b'2 797 1.0\\n',\n",
       " b'2 808 1.0\\n',\n",
       " b'2 815 2.0\\n',\n",
       " b'2 816 2.0\\n',\n",
       " b'2 819 1.0\\n',\n",
       " b'2 831 9.0\\n',\n",
       " b'2 832 1.0\\n',\n",
       " b'2 845 1.0\\n',\n",
       " b'2 848 2.0\\n',\n",
       " b'2 853 1.0\\n',\n",
       " b'2 860 1.0\\n',\n",
       " b'2 867 1.0\\n',\n",
       " b'2 869 2.0\\n',\n",
       " b'2 886 1.0\\n',\n",
       " b'2 895 1.0\\n',\n",
       " b'2 902 3.0\\n',\n",
       " b'2 919 1.0\\n',\n",
       " b'2 946 2.0\\n',\n",
       " b'2 959 1.0\\n',\n",
       " b'2 984 1.0\\n',\n",
       " b'2 1095 2.0\\n',\n",
       " b'2 1233 1.0\\n',\n",
       " b'2 1256 1.0\\n',\n",
       " b'2 1276 1.0\\n',\n",
       " b'2 1292 1.0\\n',\n",
       " b'2 1374 1.0\\n',\n",
       " b'2 1381 1.0\\n',\n",
       " b'2 1425 2.0\\n',\n",
       " b'2 1434 2.0\\n',\n",
       " b'2 1437 1.0\\n',\n",
       " b'2 1586 1.0\\n',\n",
       " b'2 1600 1.0\\n',\n",
       " b'2 1601 1.0\\n',\n",
       " b'2 1602 1.0\\n',\n",
       " b'2 1608 1.0\\n',\n",
       " b'2 1613 1.0\\n',\n",
       " b'2 1628 1.0\\n',\n",
       " b'2 1636 1.0\\n',\n",
       " b'2 1638 2.0\\n',\n",
       " b'2 1645 1.0\\n',\n",
       " b'2 1647 5.0\\n',\n",
       " b'2 1651 1.0\\n',\n",
       " b'2 1655 2.0\\n',\n",
       " b'2 1657 1.0\\n',\n",
       " b'2 1664 4.0\\n',\n",
       " b'2 1671 3.0\\n',\n",
       " b'2 1696 1.0\\n',\n",
       " b'2 1701 1.0\\n',\n",
       " b'2 1705 1.0\\n',\n",
       " b'2 1718 1.0\\n',\n",
       " b'2 1719 1.0\\n',\n",
       " b'2 1723 1.0\\n',\n",
       " b'2 1728 1.0\\n',\n",
       " b'2 1828 1.0\\n',\n",
       " b'2 1849 1.0\\n',\n",
       " b'2 1864 1.0\\n',\n",
       " b'2 1867 1.0\\n',\n",
       " b'2 1876 2.0\\n',\n",
       " b'2 1878 1.0\\n',\n",
       " b'2 1887 1.0\\n',\n",
       " b'2 1888 6.0\\n',\n",
       " b'2 1893 1.0\\n',\n",
       " b'2 1908 1.0\\n',\n",
       " b'2 1917 1.0\\n',\n",
       " b'2 1924 1.0\\n',\n",
       " b'2 1936 1.0\\n',\n",
       " b'2 1938 3.0\\n',\n",
       " b'2 1943 3.0\\n',\n",
       " b'2 1951 1.0\\n',\n",
       " b'2 1952 1.0\\n',\n",
       " b'2 1954 10.0\\n',\n",
       " b'2 1956 2.0\\n',\n",
       " b'2 1958 1.0\\n',\n",
       " b'2 1969 1.0\\n',\n",
       " b'2 1972 1.0\\n',\n",
       " b'2 1977 2.0\\n',\n",
       " b'2 1984 3.0\\n',\n",
       " b'2 1987 2.0\\n',\n",
       " b'2 1996 1.0\\n',\n",
       " b'2 1998 3.0\\n',\n",
       " b'2 2000 2.0\\n',\n",
       " b'2 2002 10.0\\n',\n",
       " b'2 2009 2.0\\n',\n",
       " b'2 2017 1.0\\n',\n",
       " b'2 2019 1.0\\n',\n",
       " b'2 2027 3.0\\n',\n",
       " b'2 2033 1.0\\n',\n",
       " b'2 2043 2.0\\n',\n",
       " b'2 2048 2.0\\n',\n",
       " b'2 2052 1.0\\n',\n",
       " b'2 2059 3.0\\n',\n",
       " b'2 2062 2.0\\n',\n",
       " b'2 2071 2.0\\n',\n",
       " b'2 2073 1.0\\n',\n",
       " b'2 2084 1.0\\n',\n",
       " b'2 2087 1.0\\n',\n",
       " b'2 2100 1.0\\n',\n",
       " b'2 2102 1.0\\n',\n",
       " b'2 2110 2.0\\n',\n",
       " b'2 2111 1.0\\n',\n",
       " b'2 2115 2.0\\n',\n",
       " b'2 2119 1.0\\n',\n",
       " b'2 2120 1.0\\n',\n",
       " b'2 2121 1.0\\n',\n",
       " b'2 2122 1.0\\n',\n",
       " b'2 2124 3.0\\n',\n",
       " b'2 2141 1.0\\n',\n",
       " b'2 2150 1.0\\n',\n",
       " b'2 2156 1.0\\n',\n",
       " b'2 2162 6.0\\n',\n",
       " b'2 2175 4.0\\n',\n",
       " b'2 2183 5.0\\n',\n",
       " b'2 2187 2.0\\n',\n",
       " b'2 2192 1.0\\n',\n",
       " b'2 2195 1.0\\n',\n",
       " b'2 2196 1.0\\n',\n",
       " b'2 2198 1.0\\n',\n",
       " b'2 2208 1.0\\n',\n",
       " b'2 2215 2.0\\n',\n",
       " b'2 2219 2.0\\n',\n",
       " b'2 2225 1.0\\n',\n",
       " b'3 1 2.0\\n',\n",
       " b'3 2 1.0\\n',\n",
       " b'3 7 1.0\\n',\n",
       " b'3 13 2.0\\n',\n",
       " b'3 14 1.0\\n',\n",
       " b'3 31 1.0\\n',\n",
       " b'3 32 1.0\\n',\n",
       " b'3 35 1.0\\n',\n",
       " b'3 40 2.0\\n',\n",
       " b'3 44 1.0\\n',\n",
       " b'3 50 1.0\\n',\n",
       " b'3 52 1.0\\n',\n",
       " b'3 54 1.0\\n',\n",
       " b'3 56 1.0\\n',\n",
       " b'3 65 1.0\\n',\n",
       " b'3 68 2.0\\n',\n",
       " b'3 73 1.0\\n',\n",
       " b'3 75 1.0\\n',\n",
       " b'3 89 1.0\\n',\n",
       " b'3 90 1.0\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "Here, we will turn this into a list of tuples representing a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01). Remember the description of the file from above:\n",
    "\n",
    "*   *bbc.mtx* is a list: first column is **wordID**, second is **articleID** and the third is the number of times that word appeared in that article.\n",
    "\n",
    "So, if word 1 appears in article 3, 2 times, one element of our list will be:\n",
    "\n",
    "`(1, 3, 2)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 1),\n",
       " (1, 7, 2),\n",
       " (1, 11, 1),\n",
       " (1, 14, 1),\n",
       " (1, 15, 2),\n",
       " (1, 19, 2),\n",
       " (1, 21, 1),\n",
       " (1, 29, 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsemat = [tuple(map(int,map(float,c.split()))) for c in content]\n",
    "# Let's examine the first few elements\n",
    "sparsemat[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preparing Sparse Matrix data for NMF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [coo matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01) function to turn the sparse matrix into an array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "rows = [x[0] for x in sparsemat]\n",
    "cols = [x[1] for x in sparsemat]\n",
    "values = [x[2] for x in sparsemat]\n",
    "coo = coo_matrix((values, (rows, cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF is a way of decomposing a matrix of documents and words so that one of the matrices can be interpreted as the \"loadings\" or \"weights\" of each word on a topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [the NMF documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01) and the [examples of topic extraction using NMF and LDA](http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Here, we will import `NMF`, define a model object with 5 components, and `fit_transform` the data created above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9636, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Surpress warnings from using older version of sklearn:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=5, init='random', random_state=818)\n",
    "doc_topic = model.fit_transform(coo)\n",
    "\n",
    "doc_topic.shape\n",
    "# we should have 9636 observations (articles) and five latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find feature with highest value per doc\n",
    "np.argmax(doc_topic, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:\n",
    "\n",
    "Check out the `components` of this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2226)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is five rows, each of which is a \"topic\" containing the weights of each word on that topic. The exercise is to *get a list of the top 10 words for each topic*. We can just store this in a list of lists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Just like we read in the data above, we'll have to read in the words from the `bbc.terms` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.terms') as r:\n",
    "    content = r.readlines()\n",
    "words = [c.split()[0] for c in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = []\n",
    "for r in model.components_:\n",
    "    a = sorted([(v,i) for i,v in enumerate(r)],reverse=True)[0:12]\n",
    "    topic_words.append([words[e[1]] for e in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'bondi',\n",
       "  b'stanlei',\n",
       "  b'continent',\n",
       "  b'mortgag',\n",
       "  b'bare',\n",
       "  b'least',\n",
       "  b'extent',\n",
       "  b'200',\n",
       "  b'leav',\n",
       "  b'frustrat',\n",
       "  b'yuan',\n",
       "  b'industri'],\n",
       " [b'manipul',\n",
       "  b'teenag',\n",
       "  b'drawn',\n",
       "  b'go',\n",
       "  b'prosecutor',\n",
       "  b'herbert',\n",
       "  b'host',\n",
       "  b'protest',\n",
       "  b'hike',\n",
       "  b'nation',\n",
       "  b'calcul',\n",
       "  b'power'],\n",
       " [b'dimens',\n",
       "  b'hous',\n",
       "  b'march',\n",
       "  b'wider',\n",
       "  b'owner',\n",
       "  b'intend',\n",
       "  b'declin',\n",
       "  b'forc',\n",
       "  b'posit',\n",
       "  b'founder',\n",
       "  b'york',\n",
       "  b'unavail'],\n",
       " [b'rome',\n",
       "  b'ft',\n",
       "  b'regain',\n",
       "  b'lawmak',\n",
       "  b'outright',\n",
       "  b'resum',\n",
       "  b'childhood',\n",
       "  b'greatest',\n",
       "  b'citi',\n",
       "  b'stagnat',\n",
       "  b'crown',\n",
       "  b'bodi'],\n",
       " [b'build',\n",
       "  b'empir',\n",
       "  b'isol',\n",
       "  b'\\xc2\\xa312',\n",
       "  b'restructur',\n",
       "  b'closer',\n",
       "  b'plung',\n",
       "  b'depreci',\n",
       "  b'durham',\n",
       "  b'race',\n",
       "  b'juli',\n",
       "  b'segreg']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, each set of words relates to the corresponding topic (ie the first set of words relates to topic 'Business', etc.)\n",
    "topic_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data had 5 topics, as listed in `bbc.docs` (which these topic words relate to).\n",
    "\n",
    "```\n",
    "Business\n",
    "Entertainment\n",
    "Politics\n",
    "Sport\n",
    "Tech\n",
    "```\n",
    "\n",
    "In \"real life\", we would have found a way to use these to inform the model. But for this little demo, we can just compare the recovered topics to the original ones. And they seem to match reasonably well. The order is different, which is to be expected in this kind of model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'business.001\\n',\n",
       " b'business.002\\n',\n",
       " b'business.003\\n',\n",
       " b'business.004\\n',\n",
       " b'business.005\\n',\n",
       " b'business.006\\n',\n",
       " b'business.007\\n',\n",
       " b'business.008\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.docs') as r:\n",
    "    doc_content = r.readlines()\n",
    "    \n",
    "doc_content[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
