{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>70</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.170</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>68</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>39.9</td>\n",
       "      <td>0.381</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.355</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>145</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.163</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.206</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "471               0                     137              70              38   \n",
       "452               0                      91              68              32   \n",
       "209               7                     184              84              33   \n",
       "498               7                     195              70              33   \n",
       "626               0                     125              68               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "471        0  33.2              0.170   22             0  \n",
       "452      210  39.9              0.381   25             0  \n",
       "209        0  35.5              0.355   41             1  \n",
       "498      145  25.1              0.163   55             1  \n",
       "626        0  24.7              0.206   21             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.825\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected model \n",
    "# - Input size: 8-dimensional\n",
    "# - Hidden layers: 2 layers, 12 hidden nodes/each, relu activation\n",
    "# - Dense layers: we specify number of OUTPUT units; for the first layer we specify the input_shape, too\n",
    "# - Activation: we can either add as layer Activation(...) or as parameter of Dense(activation=...)\n",
    "# - Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(units=12, input_shape=(8,), activation='relu'))\n",
    "model_1.add(Dense(units=12, input_shape=(8,), activation='relu'))\n",
    "model_1.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 277\n",
      "Trainable params: 277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 565us/step - loss: 0.8116 - accuracy: 0.6528 - val_loss: 0.8837 - val_accuracy: 0.6458\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.7935 - accuracy: 0.6528 - val_loss: 0.8620 - val_accuracy: 0.6458\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.7774 - accuracy: 0.6493 - val_loss: 0.8428 - val_accuracy: 0.6406\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.7630 - accuracy: 0.6510 - val_loss: 0.8256 - val_accuracy: 0.6406\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.7502 - accuracy: 0.6493 - val_loss: 0.8103 - val_accuracy: 0.6406\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7386 - accuracy: 0.6510 - val_loss: 0.7964 - val_accuracy: 0.6406\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7284 - accuracy: 0.6510 - val_loss: 0.7840 - val_accuracy: 0.6406\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.7190 - accuracy: 0.6528 - val_loss: 0.7728 - val_accuracy: 0.6354\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.7104 - accuracy: 0.6493 - val_loss: 0.7626 - val_accuracy: 0.6354\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7027 - accuracy: 0.6493 - val_loss: 0.7534 - val_accuracy: 0.6302\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6956 - accuracy: 0.6510 - val_loss: 0.7449 - val_accuracy: 0.6302\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6891 - accuracy: 0.6510 - val_loss: 0.7372 - val_accuracy: 0.6250\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6831 - accuracy: 0.6545 - val_loss: 0.7300 - val_accuracy: 0.6250\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6775 - accuracy: 0.6528 - val_loss: 0.7234 - val_accuracy: 0.6250\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6724 - accuracy: 0.6528 - val_loss: 0.7172 - val_accuracy: 0.6250\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6674 - accuracy: 0.6545 - val_loss: 0.7115 - val_accuracy: 0.6250\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6628 - accuracy: 0.6580 - val_loss: 0.7062 - val_accuracy: 0.6250\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6584 - accuracy: 0.6562 - val_loss: 0.7012 - val_accuracy: 0.6250\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6542 - accuracy: 0.6580 - val_loss: 0.6963 - val_accuracy: 0.6302\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6503 - accuracy: 0.6597 - val_loss: 0.6918 - val_accuracy: 0.6302\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6465 - accuracy: 0.6580 - val_loss: 0.6875 - val_accuracy: 0.6302\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6428 - accuracy: 0.6615 - val_loss: 0.6834 - val_accuracy: 0.6354\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6394 - accuracy: 0.6632 - val_loss: 0.6795 - val_accuracy: 0.6406\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6361 - accuracy: 0.6615 - val_loss: 0.6759 - val_accuracy: 0.6406\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6329 - accuracy: 0.6615 - val_loss: 0.6723 - val_accuracy: 0.6406\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6298 - accuracy: 0.6615 - val_loss: 0.6690 - val_accuracy: 0.6406\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6268 - accuracy: 0.6684 - val_loss: 0.6657 - val_accuracy: 0.6406\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6239 - accuracy: 0.6667 - val_loss: 0.6626 - val_accuracy: 0.6406\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6210 - accuracy: 0.6667 - val_loss: 0.6596 - val_accuracy: 0.6458\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6183 - accuracy: 0.6667 - val_loss: 0.6567 - val_accuracy: 0.6615\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6155 - accuracy: 0.6649 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6129 - accuracy: 0.6632 - val_loss: 0.6511 - val_accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6103 - accuracy: 0.6632 - val_loss: 0.6484 - val_accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6078 - accuracy: 0.6667 - val_loss: 0.6458 - val_accuracy: 0.6719\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6053 - accuracy: 0.6667 - val_loss: 0.6434 - val_accuracy: 0.6823\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6030 - accuracy: 0.6684 - val_loss: 0.6410 - val_accuracy: 0.6823\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6006 - accuracy: 0.6701 - val_loss: 0.6386 - val_accuracy: 0.6823\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5984 - accuracy: 0.6684 - val_loss: 0.6364 - val_accuracy: 0.6927\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5962 - accuracy: 0.6684 - val_loss: 0.6341 - val_accuracy: 0.6927\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5939 - accuracy: 0.6701 - val_loss: 0.6320 - val_accuracy: 0.6927\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5919 - accuracy: 0.6684 - val_loss: 0.6299 - val_accuracy: 0.6823\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5898 - accuracy: 0.6684 - val_loss: 0.6279 - val_accuracy: 0.6823\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5878 - accuracy: 0.6719 - val_loss: 0.6259 - val_accuracy: 0.6823\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.5859 - accuracy: 0.6771 - val_loss: 0.6240 - val_accuracy: 0.6823\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5840 - accuracy: 0.6788 - val_loss: 0.6221 - val_accuracy: 0.6823\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5821 - accuracy: 0.6771 - val_loss: 0.6203 - val_accuracy: 0.6771\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5802 - accuracy: 0.6806 - val_loss: 0.6186 - val_accuracy: 0.6771\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5785 - accuracy: 0.6788 - val_loss: 0.6169 - val_accuracy: 0.6771\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5767 - accuracy: 0.6806 - val_loss: 0.6153 - val_accuracy: 0.6771\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5749 - accuracy: 0.6806 - val_loss: 0.6136 - val_accuracy: 0.6771\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5732 - accuracy: 0.6823 - val_loss: 0.6121 - val_accuracy: 0.6771\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5715 - accuracy: 0.6858 - val_loss: 0.6105 - val_accuracy: 0.6771\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5699 - accuracy: 0.6892 - val_loss: 0.6090 - val_accuracy: 0.6823\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5682 - accuracy: 0.6910 - val_loss: 0.6076 - val_accuracy: 0.6875\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5666 - accuracy: 0.6927 - val_loss: 0.6061 - val_accuracy: 0.6875\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5651 - accuracy: 0.6910 - val_loss: 0.6047 - val_accuracy: 0.6875\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 37us/step - loss: 0.5636 - accuracy: 0.6910 - val_loss: 0.6034 - val_accuracy: 0.6875\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5622 - accuracy: 0.6927 - val_loss: 0.6021 - val_accuracy: 0.6875\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5607 - accuracy: 0.6927 - val_loss: 0.6008 - val_accuracy: 0.6875\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5592 - accuracy: 0.6944 - val_loss: 0.5995 - val_accuracy: 0.6927\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5577 - accuracy: 0.6944 - val_loss: 0.5982 - val_accuracy: 0.6979\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.5564 - accuracy: 0.6944 - val_loss: 0.5969 - val_accuracy: 0.6979\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5549 - accuracy: 0.6944 - val_loss: 0.5957 - val_accuracy: 0.6979\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5536 - accuracy: 0.6927 - val_loss: 0.5945 - val_accuracy: 0.6979\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5523 - accuracy: 0.6944 - val_loss: 0.5934 - val_accuracy: 0.6979\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5509 - accuracy: 0.7031 - val_loss: 0.5922 - val_accuracy: 0.6927\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5496 - accuracy: 0.6997 - val_loss: 0.5910 - val_accuracy: 0.6927\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5483 - accuracy: 0.6997 - val_loss: 0.5899 - val_accuracy: 0.6927\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5471 - accuracy: 0.6997 - val_loss: 0.5888 - val_accuracy: 0.6875\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5458 - accuracy: 0.7014 - val_loss: 0.5877 - val_accuracy: 0.6875\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5446 - accuracy: 0.6979 - val_loss: 0.5866 - val_accuracy: 0.6875\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5434 - accuracy: 0.7031 - val_loss: 0.5856 - val_accuracy: 0.6875\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5422 - accuracy: 0.6997 - val_loss: 0.5846 - val_accuracy: 0.6875\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5410 - accuracy: 0.6997 - val_loss: 0.5837 - val_accuracy: 0.6875\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5399 - accuracy: 0.7014 - val_loss: 0.5827 - val_accuracy: 0.6875\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5388 - accuracy: 0.7049 - val_loss: 0.5817 - val_accuracy: 0.6875\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5377 - accuracy: 0.7049 - val_loss: 0.5808 - val_accuracy: 0.6875\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5365 - accuracy: 0.7066 - val_loss: 0.5799 - val_accuracy: 0.6875\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5354 - accuracy: 0.7049 - val_loss: 0.5789 - val_accuracy: 0.6875\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5343 - accuracy: 0.7083 - val_loss: 0.5780 - val_accuracy: 0.6927\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5333 - accuracy: 0.7083 - val_loss: 0.5772 - val_accuracy: 0.6927\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5322 - accuracy: 0.7118 - val_loss: 0.5763 - val_accuracy: 0.7031\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5311 - accuracy: 0.7118 - val_loss: 0.5754 - val_accuracy: 0.6979\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5300 - accuracy: 0.7118 - val_loss: 0.5746 - val_accuracy: 0.6979\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5291 - accuracy: 0.7118 - val_loss: 0.5738 - val_accuracy: 0.7031\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5281 - accuracy: 0.7135 - val_loss: 0.5730 - val_accuracy: 0.7031\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5270 - accuracy: 0.7153 - val_loss: 0.5722 - val_accuracy: 0.7031\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5260 - accuracy: 0.7135 - val_loss: 0.5714 - val_accuracy: 0.7031\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5251 - accuracy: 0.7188 - val_loss: 0.5707 - val_accuracy: 0.7083\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5241 - accuracy: 0.7188 - val_loss: 0.5699 - val_accuracy: 0.7083\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5231 - accuracy: 0.7205 - val_loss: 0.5692 - val_accuracy: 0.7083\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5222 - accuracy: 0.7205 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5212 - accuracy: 0.7205 - val_loss: 0.5677 - val_accuracy: 0.7083\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5203 - accuracy: 0.7222 - val_loss: 0.5669 - val_accuracy: 0.7135\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5194 - accuracy: 0.7222 - val_loss: 0.5662 - val_accuracy: 0.7188\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5186 - accuracy: 0.7222 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5176 - accuracy: 0.7257 - val_loss: 0.5648 - val_accuracy: 0.7292\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5168 - accuracy: 0.7257 - val_loss: 0.5641 - val_accuracy: 0.7292\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5159 - accuracy: 0.7257 - val_loss: 0.5634 - val_accuracy: 0.7292\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5151 - accuracy: 0.7257 - val_loss: 0.5628 - val_accuracy: 0.7292\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5142 - accuracy: 0.7257 - val_loss: 0.5621 - val_accuracy: 0.7292\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5134 - accuracy: 0.7274 - val_loss: 0.5615 - val_accuracy: 0.7292\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5125 - accuracy: 0.7274 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5116 - accuracy: 0.7326 - val_loss: 0.5603 - val_accuracy: 0.7292\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5108 - accuracy: 0.7326 - val_loss: 0.5597 - val_accuracy: 0.7292\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5100 - accuracy: 0.7326 - val_loss: 0.5591 - val_accuracy: 0.7240\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5092 - accuracy: 0.7344 - val_loss: 0.5586 - val_accuracy: 0.7240\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5084 - accuracy: 0.7344 - val_loss: 0.5580 - val_accuracy: 0.7240\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5076 - accuracy: 0.7378 - val_loss: 0.5574 - val_accuracy: 0.7240\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5068 - accuracy: 0.7378 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5060 - accuracy: 0.7396 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5053 - accuracy: 0.7396 - val_loss: 0.5558 - val_accuracy: 0.7240\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.5044 - accuracy: 0.7396 - val_loss: 0.5553 - val_accuracy: 0.7240\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5037 - accuracy: 0.7396 - val_loss: 0.5547 - val_accuracy: 0.7240\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5029 - accuracy: 0.7431 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5021 - accuracy: 0.7413 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5014 - accuracy: 0.7431 - val_loss: 0.5532 - val_accuracy: 0.7240\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5006 - accuracy: 0.7413 - val_loss: 0.5527 - val_accuracy: 0.7240\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4998 - accuracy: 0.7413 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4992 - accuracy: 0.7431 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4984 - accuracy: 0.7431 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4977 - accuracy: 0.7448 - val_loss: 0.5508 - val_accuracy: 0.7344\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4970 - accuracy: 0.7465 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4963 - accuracy: 0.7517 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4956 - accuracy: 0.7483 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4948 - accuracy: 0.7500 - val_loss: 0.5491 - val_accuracy: 0.7448\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4941 - accuracy: 0.7535 - val_loss: 0.5487 - val_accuracy: 0.7448\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4935 - accuracy: 0.7517 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4927 - accuracy: 0.7535 - val_loss: 0.5478 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4921 - accuracy: 0.7535 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4914 - accuracy: 0.7552 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4907 - accuracy: 0.7535 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4900 - accuracy: 0.7535 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4893 - accuracy: 0.7552 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4887 - accuracy: 0.7535 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4880 - accuracy: 0.7552 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4873 - accuracy: 0.7552 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4868 - accuracy: 0.7552 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4861 - accuracy: 0.7535 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4854 - accuracy: 0.7535 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4848 - accuracy: 0.7535 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4843 - accuracy: 0.7535 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4836 - accuracy: 0.7552 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4830 - accuracy: 0.7569 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4824 - accuracy: 0.7587 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4818 - accuracy: 0.7587 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4812 - accuracy: 0.7569 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4806 - accuracy: 0.7569 - val_loss: 0.5409 - val_accuracy: 0.7396\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4801 - accuracy: 0.7569 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4795 - accuracy: 0.7587 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4790 - accuracy: 0.7587 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4784 - accuracy: 0.7622 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4779 - accuracy: 0.7622 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4773 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4768 - accuracy: 0.7622 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4764 - accuracy: 0.7639 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4757 - accuracy: 0.7656 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4753 - accuracy: 0.7674 - val_loss: 0.5382 - val_accuracy: 0.7448\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4748 - accuracy: 0.7674 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4723 - accuracy: 0.7674 - val_loss: 0.5367 - val_accuracy: 0.7396\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4718 - accuracy: 0.7656 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4713 - accuracy: 0.7674 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4686 - accuracy: 0.7656 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.5347 - val_accuracy: 0.7552\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.5345 - val_accuracy: 0.7552\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4670 - accuracy: 0.7708 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4665 - accuracy: 0.7674 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4661 - accuracy: 0.7674 - val_loss: 0.5338 - val_accuracy: 0.7552\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4657 - accuracy: 0.7674 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4653 - accuracy: 0.7674 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4649 - accuracy: 0.7639 - val_loss: 0.5333 - val_accuracy: 0.7604\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4645 - accuracy: 0.7691 - val_loss: 0.5332 - val_accuracy: 0.7604\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.5330 - val_accuracy: 0.7604\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4634 - accuracy: 0.7691 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4630 - accuracy: 0.7708 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4626 - accuracy: 0.7708 - val_loss: 0.5325 - val_accuracy: 0.7604\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.5323 - val_accuracy: 0.7604\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4619 - accuracy: 0.7708 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4601 - accuracy: 0.7691 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4598 - accuracy: 0.7691 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4588 - accuracy: 0.7743 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4581 - accuracy: 0.7708 - val_loss: 0.5309 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile: Set the the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(optimizer=SGD(lr = .003),\n",
    "                loss=\"binary_crossentropy\", \n",
    "                metrics=[\"accuracy\"])\n",
    "# We pass the data to the fit() function,\n",
    "# including the validation data\n",
    "# The fit function returns the run history:\n",
    "# it contains 'val_loss', 'val_accuracy', 'loss', 'accuracy'\n",
    "run_hist_1 = model_1.fit(X_train_norm,\n",
    "                         y_train,\n",
    "                         validation_data=(X_test_norm, y_test),\n",
    "                         epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like we did for the Random Forest, we generate two kinds of predictions\n",
    "# One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35208666],\n",
       "       [0.62414396],\n",
       "       [0.38794506],\n",
       "       [0.3123997 ],\n",
       "       [0.20048863],\n",
       "       [0.37356794],\n",
       "       [0.04133147],\n",
       "       [0.34499168],\n",
       "       [0.6365192 ],\n",
       "       [0.19504961]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.755\n",
      "roc-auc is 0.798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe50e83a490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5407 - accuracy: 0.7153 - val_loss: 0.5551 - val_accuracy: 0.7240\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.5404 - accuracy: 0.7153 - val_loss: 0.5548 - val_accuracy: 0.7240\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5401 - accuracy: 0.7153 - val_loss: 0.5545 - val_accuracy: 0.7240\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5397 - accuracy: 0.7153 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5394 - accuracy: 0.7153 - val_loss: 0.5539 - val_accuracy: 0.7240\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5391 - accuracy: 0.7135 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5388 - accuracy: 0.7135 - val_loss: 0.5533 - val_accuracy: 0.7240\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5385 - accuracy: 0.7135 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5382 - accuracy: 0.7153 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5378 - accuracy: 0.7170 - val_loss: 0.5524 - val_accuracy: 0.7292\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5375 - accuracy: 0.7188 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5372 - accuracy: 0.7188 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5369 - accuracy: 0.7188 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5366 - accuracy: 0.7188 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5363 - accuracy: 0.7188 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5360 - accuracy: 0.7188 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5357 - accuracy: 0.7205 - val_loss: 0.5504 - val_accuracy: 0.7344\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5353 - accuracy: 0.7240 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5351 - accuracy: 0.7257 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5348 - accuracy: 0.7257 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5344 - accuracy: 0.7257 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5341 - accuracy: 0.7257 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5338 - accuracy: 0.7257 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5336 - accuracy: 0.7257 - val_loss: 0.5484 - val_accuracy: 0.7396\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5332 - accuracy: 0.7274 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5329 - accuracy: 0.7257 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5326 - accuracy: 0.7257 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5323 - accuracy: 0.7257 - val_loss: 0.5473 - val_accuracy: 0.7396\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5320 - accuracy: 0.7274 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5318 - accuracy: 0.7274 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5314 - accuracy: 0.7274 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5311 - accuracy: 0.7292 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5309 - accuracy: 0.7309 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5306 - accuracy: 0.7309 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5303 - accuracy: 0.7309 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5300 - accuracy: 0.7309 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5297 - accuracy: 0.7309 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5294 - accuracy: 0.7326 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5291 - accuracy: 0.7326 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5288 - accuracy: 0.7326 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5286 - accuracy: 0.7344 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5283 - accuracy: 0.7344 - val_loss: 0.5436 - val_accuracy: 0.7292\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5280 - accuracy: 0.7344 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5277 - accuracy: 0.7361 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5274 - accuracy: 0.7361 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5272 - accuracy: 0.7378 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5269 - accuracy: 0.7396 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5266 - accuracy: 0.7413 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5263 - accuracy: 0.7413 - val_loss: 0.5418 - val_accuracy: 0.7292\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5261 - accuracy: 0.7448 - val_loss: 0.5416 - val_accuracy: 0.7292\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5258 - accuracy: 0.7483 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5255 - accuracy: 0.7483 - val_loss: 0.5410 - val_accuracy: 0.7292\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5252 - accuracy: 0.7500 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5249 - accuracy: 0.7483 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5247 - accuracy: 0.7500 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5244 - accuracy: 0.7535 - val_loss: 0.5401 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5241 - accuracy: 0.7569 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5239 - accuracy: 0.7569 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5236 - accuracy: 0.7569 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5233 - accuracy: 0.7587 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5231 - accuracy: 0.7569 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5228 - accuracy: 0.7535 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5225 - accuracy: 0.7552 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5223 - accuracy: 0.7535 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5220 - accuracy: 0.7552 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5218 - accuracy: 0.7552 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5215 - accuracy: 0.7569 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5212 - accuracy: 0.7552 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5210 - accuracy: 0.7569 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5207 - accuracy: 0.7552 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5204 - accuracy: 0.7552 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5202 - accuracy: 0.7552 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5199 - accuracy: 0.7552 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5197 - accuracy: 0.7552 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7552 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5192 - accuracy: 0.7552 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5189 - accuracy: 0.7569 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5187 - accuracy: 0.7569 - val_loss: 0.5349 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5184 - accuracy: 0.7569 - val_loss: 0.5346 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5182 - accuracy: 0.7569 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5179 - accuracy: 0.7569 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5177 - accuracy: 0.7569 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5174 - accuracy: 0.7569 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5172 - accuracy: 0.7569 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5169 - accuracy: 0.7569 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5167 - accuracy: 0.7569 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5164 - accuracy: 0.7552 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5162 - accuracy: 0.7552 - val_loss: 0.5326 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5160 - accuracy: 0.7552 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5157 - accuracy: 0.7569 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5155 - accuracy: 0.7552 - val_loss: 0.5320 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5153 - accuracy: 0.7535 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5150 - accuracy: 0.7535 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5148 - accuracy: 0.7535 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5145 - accuracy: 0.7535 - val_loss: 0.5311 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5141 - accuracy: 0.7517 - val_loss: 0.5307 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5138 - accuracy: 0.7535 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5136 - accuracy: 0.7517 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5134 - accuracy: 0.7535 - val_loss: 0.5301 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5131 - accuracy: 0.7535 - val_loss: 0.5299 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5129 - accuracy: 0.7535 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5127 - accuracy: 0.7535 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5124 - accuracy: 0.7535 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5122 - accuracy: 0.7535 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5120 - accuracy: 0.7535 - val_loss: 0.5289 - val_accuracy: 0.7656\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5118 - accuracy: 0.7552 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5116 - accuracy: 0.7535 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5113 - accuracy: 0.7535 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5111 - accuracy: 0.7535 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5109 - accuracy: 0.7535 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5107 - accuracy: 0.7535 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 35us/step - loss: 0.5104 - accuracy: 0.7535 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5102 - accuracy: 0.7517 - val_loss: 0.5273 - val_accuracy: 0.7552\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5271 - val_accuracy: 0.7552\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5098 - accuracy: 0.7517 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5096 - accuracy: 0.7517 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5093 - accuracy: 0.7517 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5091 - accuracy: 0.7517 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5089 - accuracy: 0.7517 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5087 - accuracy: 0.7535 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5085 - accuracy: 0.7552 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5083 - accuracy: 0.7552 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5081 - accuracy: 0.7552 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5078 - accuracy: 0.7552 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5076 - accuracy: 0.7569 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5074 - accuracy: 0.7569 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5072 - accuracy: 0.7569 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5070 - accuracy: 0.7587 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5068 - accuracy: 0.7587 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5066 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5064 - accuracy: 0.7604 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5062 - accuracy: 0.7622 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5060 - accuracy: 0.7622 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5056 - accuracy: 0.7622 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5054 - accuracy: 0.7622 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5052 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5050 - accuracy: 0.7622 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5048 - accuracy: 0.7622 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5046 - accuracy: 0.7622 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5044 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5042 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5040 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5038 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5036 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5034 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5032 - accuracy: 0.7622 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5027 - accuracy: 0.7587 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5025 - accuracy: 0.7569 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5023 - accuracy: 0.7587 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5021 - accuracy: 0.7569 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5019 - accuracy: 0.7569 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5017 - accuracy: 0.7569 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5015 - accuracy: 0.7587 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5013 - accuracy: 0.7587 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5011 - accuracy: 0.7587 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5010 - accuracy: 0.7587 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5006 - accuracy: 0.7587 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5004 - accuracy: 0.7587 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5002 - accuracy: 0.7587 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5000 - accuracy: 0.7587 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4999 - accuracy: 0.7587 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4997 - accuracy: 0.7587 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4995 - accuracy: 0.7587 - val_loss: 0.5180 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4994 - accuracy: 0.7587 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4992 - accuracy: 0.7587 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4990 - accuracy: 0.7587 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4988 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4986 - accuracy: 0.7587 - val_loss: 0.5173 - val_accuracy: 0.7708\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4985 - accuracy: 0.7587 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4983 - accuracy: 0.7587 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4981 - accuracy: 0.7587 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4979 - accuracy: 0.7587 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4978 - accuracy: 0.7587 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4976 - accuracy: 0.7587 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4974 - accuracy: 0.7587 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4973 - accuracy: 0.7604 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4971 - accuracy: 0.7604 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4969 - accuracy: 0.7622 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4968 - accuracy: 0.7604 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4965 - accuracy: 0.7639 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4963 - accuracy: 0.7656 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4960 - accuracy: 0.7656 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4956 - accuracy: 0.7656 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4955 - accuracy: 0.7656 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4953 - accuracy: 0.7656 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4951 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4950 - accuracy: 0.7656 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4948 - accuracy: 0.7656 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4943 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4940 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4939 - accuracy: 0.7639 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4936 - accuracy: 0.7656 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4934 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4933 - accuracy: 0.7639 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4929 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4928 - accuracy: 0.7639 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4927 - accuracy: 0.7639 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4924 - accuracy: 0.7639 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4922 - accuracy: 0.7639 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 193us/step - loss: 0.4919 - accuracy: 0.7639 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4918 - accuracy: 0.7639 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4916 - accuracy: 0.7622 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4915 - accuracy: 0.7639 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4912 - accuracy: 0.7639 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4911 - accuracy: 0.7639 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4908 - accuracy: 0.7639 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4906 - accuracy: 0.7622 - val_loss: 0.5106 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4905 - accuracy: 0.7622 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4902 - accuracy: 0.7622 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4901 - accuracy: 0.7604 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4899 - accuracy: 0.7622 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4898 - accuracy: 0.7622 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4895 - accuracy: 0.7622 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4894 - accuracy: 0.7622 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4892 - accuracy: 0.7622 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4891 - accuracy: 0.7622 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4890 - accuracy: 0.7639 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4888 - accuracy: 0.7622 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4887 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4886 - accuracy: 0.7639 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4884 - accuracy: 0.7639 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4883 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4882 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4880 - accuracy: 0.7639 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4878 - accuracy: 0.7639 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4875 - accuracy: 0.7639 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4874 - accuracy: 0.7639 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4873 - accuracy: 0.7639 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4871 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4870 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4869 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4868 - accuracy: 0.7639 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4866 - accuracy: 0.7622 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4865 - accuracy: 0.7622 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4864 - accuracy: 0.7622 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4863 - accuracy: 0.7622 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4862 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4859 - accuracy: 0.7622 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4858 - accuracy: 0.7622 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4857 - accuracy: 0.7622 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4856 - accuracy: 0.7622 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4854 - accuracy: 0.7622 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4852 - accuracy: 0.7622 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4851 - accuracy: 0.7622 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4850 - accuracy: 0.7622 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4848 - accuracy: 0.7622 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 191us/step - loss: 0.4847 - accuracy: 0.7622 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 357us/step - loss: 0.4846 - accuracy: 0.7622 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 278us/step - loss: 0.4845 - accuracy: 0.7622 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 407us/step - loss: 0.4844 - accuracy: 0.7622 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 408us/step - loss: 0.4843 - accuracy: 0.7622 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 193us/step - loss: 0.4841 - accuracy: 0.7622 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 280us/step - loss: 0.4840 - accuracy: 0.7622 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 312us/step - loss: 0.4839 - accuracy: 0.7622 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4838 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4837 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 85us/step - loss: 0.4836 - accuracy: 0.7622 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4835 - accuracy: 0.7622 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4834 - accuracy: 0.7622 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4833 - accuracy: 0.7622 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4831 - accuracy: 0.7622 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4830 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4829 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4828 - accuracy: 0.7622 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4827 - accuracy: 0.7622 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4826 - accuracy: 0.7622 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4825 - accuracy: 0.7622 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4824 - accuracy: 0.7622 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4823 - accuracy: 0.7622 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4821 - accuracy: 0.7622 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4820 - accuracy: 0.7622 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4819 - accuracy: 0.7622 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4817 - accuracy: 0.7622 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4817 - accuracy: 0.7622 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4816 - accuracy: 0.7622 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4815 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4813 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4812 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4811 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4810 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4809 - accuracy: 0.7622 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4808 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4807 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4807 - accuracy: 0.7622 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4806 - accuracy: 0.7604 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4804 - accuracy: 0.7604 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4803 - accuracy: 0.7604 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4803 - accuracy: 0.7604 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4801 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4801 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4799 - accuracy: 0.7622 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4799 - accuracy: 0.7622 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4798 - accuracy: 0.7639 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4796 - accuracy: 0.7622 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4795 - accuracy: 0.7639 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4794 - accuracy: 0.7656 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4793 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4792 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4791 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4790 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4789 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4788 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4787 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4786 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4786 - accuracy: 0.7656 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4785 - accuracy: 0.7656 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4783 - accuracy: 0.7656 - val_loss: 0.5009 - val_accuracy: 0.7448\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4782 - accuracy: 0.7656 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.5008 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4780 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4778 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4778 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4777 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4776 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4775 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4774 - accuracy: 0.7656 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4773 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4772 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4772 - accuracy: 0.7656 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4771 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4770 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4769 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4767 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4766 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4766 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4765 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4764 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7396\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4759 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4759 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4758 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4757 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4756 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4754 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7396\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4753 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7396\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4752 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7396\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4752 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7396\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4751 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7396\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4750 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7396\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7396\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7396\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7396\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4746 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7396\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4746 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4745 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4744 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4743 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4743 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4742 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4739 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4739 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 195us/step - loss: 0.4738 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 147us/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7396\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7396\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7396\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4735 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7396\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4734 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7396\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4733 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7396\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4733 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7396\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4732 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7396\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4731 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7396\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4731 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.4729 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 304us/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7396\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 274us/step - loss: 0.4726 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7396\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 200us/step - loss: 0.4726 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7396\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 329us/step - loss: 0.4725 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7396\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4724 - accuracy: 0.7656 - val_loss: 0.4968 - val_accuracy: 0.7396\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 207us/step - loss: 0.4724 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7396\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 236us/step - loss: 0.4723 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7396\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 336us/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4720 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4719 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4719 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4718 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4717 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4717 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4716 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4715 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4715 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4714 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4714 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4713 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4712 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4712 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4711 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4711 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4710 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4707 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4707 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4706 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4704 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4704 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4703 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4703 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4702 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4701 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4693 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4692 - accuracy: 0.7708 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4691 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4691 - accuracy: 0.7708 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4686 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4686 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 225us/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 277us/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 201us/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 299us/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 255us/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 231us/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 176us/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
      "Epoch 558/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 74us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4650 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7344\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7344\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7344\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7344\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7344\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7344\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7344\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7344\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7344\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7344\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7344\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7344\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7344\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7344\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7344\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7344\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7344\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7344\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7344\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7344\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7344\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7344\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7344\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7344\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7344\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7344\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7396\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4624 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4622 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7396\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 181us/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 274us/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 240us/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 193us/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7396\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 256us/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 309us/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 251us/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 269us/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7396\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7396\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4612 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 203us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 129us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 191us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 207us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 282us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 137us/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 190us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 288us/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 176us/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 194us/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 185us/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 182us/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 174us/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 188us/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 381us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 50us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 228us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 265us/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 249us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 268us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 307us/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe50ea005d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(units=6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(units=6, activation=\"relu\"))\n",
    "model_2.add(Dense(units=1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 577us/step - loss: 0.9278 - accuracy: 0.4896 - val_loss: 0.9467 - val_accuracy: 0.4948\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.8979 - accuracy: 0.4896 - val_loss: 0.9143 - val_accuracy: 0.5000\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.8721 - accuracy: 0.4896 - val_loss: 0.8859 - val_accuracy: 0.5104\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.8498 - accuracy: 0.4931 - val_loss: 0.8607 - val_accuracy: 0.5104\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.8303 - accuracy: 0.5017 - val_loss: 0.8383 - val_accuracy: 0.5156\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.8133 - accuracy: 0.5156 - val_loss: 0.8187 - val_accuracy: 0.5312\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.7983 - accuracy: 0.5312 - val_loss: 0.8012 - val_accuracy: 0.5417\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.7849 - accuracy: 0.5417 - val_loss: 0.7858 - val_accuracy: 0.5469\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.7730 - accuracy: 0.5521 - val_loss: 0.7719 - val_accuracy: 0.5521\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.7624 - accuracy: 0.5608 - val_loss: 0.7598 - val_accuracy: 0.5729\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.7529 - accuracy: 0.5851 - val_loss: 0.7491 - val_accuracy: 0.6094\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7444 - accuracy: 0.6059 - val_loss: 0.7397 - val_accuracy: 0.6146\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7367 - accuracy: 0.6128 - val_loss: 0.7316 - val_accuracy: 0.6198\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7298 - accuracy: 0.6250 - val_loss: 0.7244 - val_accuracy: 0.6198\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7235 - accuracy: 0.6302 - val_loss: 0.7179 - val_accuracy: 0.6250\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7176 - accuracy: 0.6354 - val_loss: 0.7119 - val_accuracy: 0.6250\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7122 - accuracy: 0.6372 - val_loss: 0.7065 - val_accuracy: 0.6250\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7072 - accuracy: 0.6406 - val_loss: 0.7015 - val_accuracy: 0.6250\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7025 - accuracy: 0.6406 - val_loss: 0.6968 - val_accuracy: 0.6250\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6979 - accuracy: 0.6424 - val_loss: 0.6924 - val_accuracy: 0.6250\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6936 - accuracy: 0.6441 - val_loss: 0.6883 - val_accuracy: 0.6250\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6896 - accuracy: 0.6458 - val_loss: 0.6844 - val_accuracy: 0.6302\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6858 - accuracy: 0.6458 - val_loss: 0.6807 - val_accuracy: 0.6302\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6821 - accuracy: 0.6458 - val_loss: 0.6772 - val_accuracy: 0.6354\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.6787 - accuracy: 0.6458 - val_loss: 0.6738 - val_accuracy: 0.6354\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6755 - accuracy: 0.6476 - val_loss: 0.6707 - val_accuracy: 0.6354\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6724 - accuracy: 0.6493 - val_loss: 0.6676 - val_accuracy: 0.6562\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6693 - accuracy: 0.6545 - val_loss: 0.6646 - val_accuracy: 0.6719\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6664 - accuracy: 0.6667 - val_loss: 0.6617 - val_accuracy: 0.6771\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6635 - accuracy: 0.6684 - val_loss: 0.6589 - val_accuracy: 0.6927\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6607 - accuracy: 0.6701 - val_loss: 0.6562 - val_accuracy: 0.6927\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6580 - accuracy: 0.6719 - val_loss: 0.6535 - val_accuracy: 0.6979\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6554 - accuracy: 0.6736 - val_loss: 0.6509 - val_accuracy: 0.6927\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6529 - accuracy: 0.6788 - val_loss: 0.6484 - val_accuracy: 0.6979\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6504 - accuracy: 0.6823 - val_loss: 0.6460 - val_accuracy: 0.6927\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6480 - accuracy: 0.6823 - val_loss: 0.6436 - val_accuracy: 0.6927\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6457 - accuracy: 0.6823 - val_loss: 0.6413 - val_accuracy: 0.7031\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6434 - accuracy: 0.6892 - val_loss: 0.6391 - val_accuracy: 0.7031\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6411 - accuracy: 0.6910 - val_loss: 0.6369 - val_accuracy: 0.7135\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6390 - accuracy: 0.6962 - val_loss: 0.6348 - val_accuracy: 0.7083\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6369 - accuracy: 0.6997 - val_loss: 0.6327 - val_accuracy: 0.7031\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6348 - accuracy: 0.7014 - val_loss: 0.6306 - val_accuracy: 0.6979\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6328 - accuracy: 0.7083 - val_loss: 0.6286 - val_accuracy: 0.6927\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6308 - accuracy: 0.7118 - val_loss: 0.6267 - val_accuracy: 0.6927\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6289 - accuracy: 0.7101 - val_loss: 0.6248 - val_accuracy: 0.6927\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6270 - accuracy: 0.7101 - val_loss: 0.6229 - val_accuracy: 0.6927\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.6252 - accuracy: 0.7083 - val_loss: 0.6211 - val_accuracy: 0.6927\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6234 - accuracy: 0.7083 - val_loss: 0.6193 - val_accuracy: 0.6927\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.6216 - accuracy: 0.7066 - val_loss: 0.6176 - val_accuracy: 0.6979\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6199 - accuracy: 0.7083 - val_loss: 0.6158 - val_accuracy: 0.6979\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6182 - accuracy: 0.7083 - val_loss: 0.6141 - val_accuracy: 0.7031\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6165 - accuracy: 0.7118 - val_loss: 0.6125 - val_accuracy: 0.7031\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6149 - accuracy: 0.7083 - val_loss: 0.6108 - val_accuracy: 0.7083\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6133 - accuracy: 0.7083 - val_loss: 0.6092 - val_accuracy: 0.7083\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6117 - accuracy: 0.7083 - val_loss: 0.6077 - val_accuracy: 0.7083\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6102 - accuracy: 0.7083 - val_loss: 0.6061 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6087 - accuracy: 0.7083 - val_loss: 0.6046 - val_accuracy: 0.7083\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6072 - accuracy: 0.7083 - val_loss: 0.6031 - val_accuracy: 0.7083\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6058 - accuracy: 0.7083 - val_loss: 0.6017 - val_accuracy: 0.7083\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6043 - accuracy: 0.7083 - val_loss: 0.6003 - val_accuracy: 0.7135\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6030 - accuracy: 0.7118 - val_loss: 0.5989 - val_accuracy: 0.7083\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6016 - accuracy: 0.7101 - val_loss: 0.5975 - val_accuracy: 0.7135\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6002 - accuracy: 0.7101 - val_loss: 0.5961 - val_accuracy: 0.7135\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5989 - accuracy: 0.7101 - val_loss: 0.5948 - val_accuracy: 0.7135\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5976 - accuracy: 0.7083 - val_loss: 0.5935 - val_accuracy: 0.7135\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5963 - accuracy: 0.7118 - val_loss: 0.5922 - val_accuracy: 0.7135\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5950 - accuracy: 0.7118 - val_loss: 0.5909 - val_accuracy: 0.7135\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5938 - accuracy: 0.7153 - val_loss: 0.5897 - val_accuracy: 0.7135\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5925 - accuracy: 0.7135 - val_loss: 0.5885 - val_accuracy: 0.7135\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5914 - accuracy: 0.7170 - val_loss: 0.5873 - val_accuracy: 0.7135\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5902 - accuracy: 0.7170 - val_loss: 0.5861 - val_accuracy: 0.7135\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5890 - accuracy: 0.7153 - val_loss: 0.5850 - val_accuracy: 0.7135\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5879 - accuracy: 0.7170 - val_loss: 0.5838 - val_accuracy: 0.7135\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5867 - accuracy: 0.7188 - val_loss: 0.5827 - val_accuracy: 0.7135\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5856 - accuracy: 0.7188 - val_loss: 0.5816 - val_accuracy: 0.7135\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5846 - accuracy: 0.7188 - val_loss: 0.5805 - val_accuracy: 0.7135\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5835 - accuracy: 0.7188 - val_loss: 0.5795 - val_accuracy: 0.7188\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5825 - accuracy: 0.7205 - val_loss: 0.5784 - val_accuracy: 0.7188\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5814 - accuracy: 0.7205 - val_loss: 0.5774 - val_accuracy: 0.7188\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5804 - accuracy: 0.7205 - val_loss: 0.5764 - val_accuracy: 0.7188\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5794 - accuracy: 0.7205 - val_loss: 0.5755 - val_accuracy: 0.7188\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5784 - accuracy: 0.7205 - val_loss: 0.5745 - val_accuracy: 0.7188\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5774 - accuracy: 0.7205 - val_loss: 0.5736 - val_accuracy: 0.7188\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5764 - accuracy: 0.7222 - val_loss: 0.5727 - val_accuracy: 0.7188\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5755 - accuracy: 0.7222 - val_loss: 0.5718 - val_accuracy: 0.7135\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5745 - accuracy: 0.7240 - val_loss: 0.5709 - val_accuracy: 0.7135\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5736 - accuracy: 0.7222 - val_loss: 0.5700 - val_accuracy: 0.7135\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5727 - accuracy: 0.7240 - val_loss: 0.5691 - val_accuracy: 0.7135\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5718 - accuracy: 0.7240 - val_loss: 0.5683 - val_accuracy: 0.7135\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5709 - accuracy: 0.7240 - val_loss: 0.5675 - val_accuracy: 0.7188\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5700 - accuracy: 0.7240 - val_loss: 0.5666 - val_accuracy: 0.7188\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5692 - accuracy: 0.7257 - val_loss: 0.5658 - val_accuracy: 0.7188\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5683 - accuracy: 0.7257 - val_loss: 0.5650 - val_accuracy: 0.7135\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5675 - accuracy: 0.7257 - val_loss: 0.5643 - val_accuracy: 0.7135\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5666 - accuracy: 0.7240 - val_loss: 0.5635 - val_accuracy: 0.7135\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5658 - accuracy: 0.7257 - val_loss: 0.5627 - val_accuracy: 0.7135\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5650 - accuracy: 0.7240 - val_loss: 0.5620 - val_accuracy: 0.7135\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5642 - accuracy: 0.7240 - val_loss: 0.5612 - val_accuracy: 0.7188\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5634 - accuracy: 0.7240 - val_loss: 0.5605 - val_accuracy: 0.7188\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5626 - accuracy: 0.7240 - val_loss: 0.5598 - val_accuracy: 0.7188\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5618 - accuracy: 0.7240 - val_loss: 0.5591 - val_accuracy: 0.7188\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5610 - accuracy: 0.7240 - val_loss: 0.5584 - val_accuracy: 0.7188\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5602 - accuracy: 0.7240 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5595 - accuracy: 0.7257 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5587 - accuracy: 0.7257 - val_loss: 0.5564 - val_accuracy: 0.7188\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5579 - accuracy: 0.7240 - val_loss: 0.5558 - val_accuracy: 0.7188\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5572 - accuracy: 0.7240 - val_loss: 0.5552 - val_accuracy: 0.7188\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5565 - accuracy: 0.7240 - val_loss: 0.5546 - val_accuracy: 0.7188\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5558 - accuracy: 0.7292 - val_loss: 0.5540 - val_accuracy: 0.7188\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5551 - accuracy: 0.7274 - val_loss: 0.5534 - val_accuracy: 0.7188\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5544 - accuracy: 0.7274 - val_loss: 0.5528 - val_accuracy: 0.7188\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5537 - accuracy: 0.7274 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
      "Epoch 113/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 39us/step - loss: 0.5531 - accuracy: 0.7274 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5524 - accuracy: 0.7274 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5518 - accuracy: 0.7292 - val_loss: 0.5506 - val_accuracy: 0.7188\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5511 - accuracy: 0.7292 - val_loss: 0.5500 - val_accuracy: 0.7188\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5505 - accuracy: 0.7292 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5499 - accuracy: 0.7292 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5492 - accuracy: 0.7292 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5486 - accuracy: 0.7292 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5480 - accuracy: 0.7292 - val_loss: 0.5475 - val_accuracy: 0.7188\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5474 - accuracy: 0.7309 - val_loss: 0.5470 - val_accuracy: 0.7188\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5468 - accuracy: 0.7326 - val_loss: 0.5466 - val_accuracy: 0.7188\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5462 - accuracy: 0.7361 - val_loss: 0.5461 - val_accuracy: 0.7188\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5456 - accuracy: 0.7378 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5450 - accuracy: 0.7378 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5444 - accuracy: 0.7378 - val_loss: 0.5448 - val_accuracy: 0.7188\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5438 - accuracy: 0.7378 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5433 - accuracy: 0.7378 - val_loss: 0.5439 - val_accuracy: 0.7188\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5426 - accuracy: 0.7396 - val_loss: 0.5435 - val_accuracy: 0.7188\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5421 - accuracy: 0.7396 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5415 - accuracy: 0.7413 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5409 - accuracy: 0.7396 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5403 - accuracy: 0.7396 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5397 - accuracy: 0.7396 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5391 - accuracy: 0.7396 - val_loss: 0.5412 - val_accuracy: 0.7188\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5386 - accuracy: 0.7396 - val_loss: 0.5408 - val_accuracy: 0.7188\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5381 - accuracy: 0.7396 - val_loss: 0.5405 - val_accuracy: 0.7188\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5375 - accuracy: 0.7413 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5370 - accuracy: 0.7413 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5364 - accuracy: 0.7413 - val_loss: 0.5395 - val_accuracy: 0.7188\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5359 - accuracy: 0.7413 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5354 - accuracy: 0.7413 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5349 - accuracy: 0.7413 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5344 - accuracy: 0.7431 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5339 - accuracy: 0.7431 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5334 - accuracy: 0.7448 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5329 - accuracy: 0.7448 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5324 - accuracy: 0.7448 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5320 - accuracy: 0.7465 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5315 - accuracy: 0.7465 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5310 - accuracy: 0.7465 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5306 - accuracy: 0.7465 - val_loss: 0.5358 - val_accuracy: 0.7188\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5301 - accuracy: 0.7465 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5296 - accuracy: 0.7465 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5292 - accuracy: 0.7465 - val_loss: 0.5350 - val_accuracy: 0.7188\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5287 - accuracy: 0.7465 - val_loss: 0.5347 - val_accuracy: 0.7188\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5283 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7188\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5278 - accuracy: 0.7465 - val_loss: 0.5342 - val_accuracy: 0.7188\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5274 - accuracy: 0.7465 - val_loss: 0.5339 - val_accuracy: 0.7188\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5269 - accuracy: 0.7465 - val_loss: 0.5336 - val_accuracy: 0.7188\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5265 - accuracy: 0.7465 - val_loss: 0.5334 - val_accuracy: 0.7188\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5260 - accuracy: 0.7465 - val_loss: 0.5331 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5256 - accuracy: 0.7465 - val_loss: 0.5329 - val_accuracy: 0.7188\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5252 - accuracy: 0.7465 - val_loss: 0.5326 - val_accuracy: 0.7188\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5247 - accuracy: 0.7465 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5243 - accuracy: 0.7483 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5239 - accuracy: 0.7483 - val_loss: 0.5319 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5231 - accuracy: 0.7483 - val_loss: 0.5314 - val_accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5226 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5222 - accuracy: 0.7500 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5218 - accuracy: 0.7483 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5214 - accuracy: 0.7483 - val_loss: 0.5305 - val_accuracy: 0.7240\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5209 - accuracy: 0.7500 - val_loss: 0.5303 - val_accuracy: 0.7240\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5205 - accuracy: 0.7483 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5197 - accuracy: 0.7500 - val_loss: 0.5297 - val_accuracy: 0.7240\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.5193 - accuracy: 0.7500 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5185 - accuracy: 0.7517 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.5181 - accuracy: 0.7517 - val_loss: 0.5289 - val_accuracy: 0.7240\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5176 - accuracy: 0.7517 - val_loss: 0.5287 - val_accuracy: 0.7240\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5173 - accuracy: 0.7535 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5168 - accuracy: 0.7535 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5165 - accuracy: 0.7552 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5160 - accuracy: 0.7552 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5156 - accuracy: 0.7552 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5152 - accuracy: 0.7569 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5148 - accuracy: 0.7569 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5144 - accuracy: 0.7552 - val_loss: 0.5273 - val_accuracy: 0.7240\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5140 - accuracy: 0.7552 - val_loss: 0.5272 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5137 - accuracy: 0.7552 - val_loss: 0.5270 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5133 - accuracy: 0.7552 - val_loss: 0.5269 - val_accuracy: 0.7292\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5129 - accuracy: 0.7552 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5126 - accuracy: 0.7569 - val_loss: 0.5265 - val_accuracy: 0.7396\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.5122 - accuracy: 0.7569 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5119 - accuracy: 0.7569 - val_loss: 0.5263 - val_accuracy: 0.7396\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5115 - accuracy: 0.7569 - val_loss: 0.5261 - val_accuracy: 0.7396\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5112 - accuracy: 0.7569 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5108 - accuracy: 0.7569 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5105 - accuracy: 0.7569 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5102 - accuracy: 0.7569 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5099 - accuracy: 0.7569 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5096 - accuracy: 0.7569 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5092 - accuracy: 0.7569 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5089 - accuracy: 0.7569 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5086 - accuracy: 0.7569 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5083 - accuracy: 0.7569 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5079 - accuracy: 0.7569 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5076 - accuracy: 0.7569 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5073 - accuracy: 0.7587 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5070 - accuracy: 0.7587 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5067 - accuracy: 0.7587 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5064 - accuracy: 0.7587 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5057 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5054 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5051 - accuracy: 0.7604 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5048 - accuracy: 0.7604 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5045 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5042 - accuracy: 0.7604 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5040 - accuracy: 0.7622 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5036 - accuracy: 0.7622 - val_loss: 0.5230 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5031 - accuracy: 0.7622 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5028 - accuracy: 0.7622 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5024 - accuracy: 0.7622 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5022 - accuracy: 0.7622 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5019 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5016 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5012 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5010 - accuracy: 0.7622 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5007 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5004 - accuracy: 0.7604 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5001 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4998 - accuracy: 0.7622 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4996 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4993 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4990 - accuracy: 0.7622 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4988 - accuracy: 0.7604 - val_loss: 0.5212 - val_accuracy: 0.7448\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4984 - accuracy: 0.7604 - val_loss: 0.5211 - val_accuracy: 0.7448\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4982 - accuracy: 0.7622 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4977 - accuracy: 0.7604 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4974 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4971 - accuracy: 0.7639 - val_loss: 0.5205 - val_accuracy: 0.7448\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4968 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4963 - accuracy: 0.7622 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4960 - accuracy: 0.7656 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4957 - accuracy: 0.7639 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4952 - accuracy: 0.7656 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4949 - accuracy: 0.7674 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4944 - accuracy: 0.7674 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4939 - accuracy: 0.7674 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4937 - accuracy: 0.7674 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4935 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4932 - accuracy: 0.7656 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4930 - accuracy: 0.7656 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4928 - accuracy: 0.7656 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4926 - accuracy: 0.7656 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4921 - accuracy: 0.7674 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4919 - accuracy: 0.7674 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4917 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4912 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4910 - accuracy: 0.7674 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4908 - accuracy: 0.7691 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4907 - accuracy: 0.7674 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4904 - accuracy: 0.7674 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4900 - accuracy: 0.7639 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4896 - accuracy: 0.7639 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4894 - accuracy: 0.7639 - val_loss: 0.5173 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4892 - accuracy: 0.7639 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4891 - accuracy: 0.7639 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4888 - accuracy: 0.7639 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4887 - accuracy: 0.7639 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4885 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4883 - accuracy: 0.7674 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4881 - accuracy: 0.7656 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4879 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4873 - accuracy: 0.7674 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4871 - accuracy: 0.7674 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4870 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4867 - accuracy: 0.7674 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4866 - accuracy: 0.7674 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4862 - accuracy: 0.7674 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4858 - accuracy: 0.7691 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4856 - accuracy: 0.7691 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4852 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4850 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4848 - accuracy: 0.7726 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4845 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4841 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4839 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4838 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4836 - accuracy: 0.7708 - val_loss: 0.5144 - val_accuracy: 0.7396\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4834 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4832 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4831 - accuracy: 0.7708 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4829 - accuracy: 0.7708 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4828 - accuracy: 0.7708 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4826 - accuracy: 0.7708 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4824 - accuracy: 0.7708 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4819 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4817 - accuracy: 0.7726 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4815 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4814 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4810 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4805 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4802 - accuracy: 0.7743 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4800 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4797 - accuracy: 0.7743 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4796 - accuracy: 0.7743 - val_loss: 0.5122 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4794 - accuracy: 0.7743 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4789 - accuracy: 0.7691 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4780 - accuracy: 0.7743 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4778 - accuracy: 0.7743 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4777 - accuracy: 0.7743 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4775 - accuracy: 0.7743 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4774 - accuracy: 0.7743 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4772 - accuracy: 0.7743 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4771 - accuracy: 0.7743 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4767 - accuracy: 0.7743 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4766 - accuracy: 0.7743 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4763 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4758 - accuracy: 0.7743 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4757 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4752 - accuracy: 0.7760 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4749 - accuracy: 0.7760 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4745 - accuracy: 0.7760 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4734 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4733 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4732 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4725 - accuracy: 0.7795 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4724 - accuracy: 0.7812 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4723 - accuracy: 0.7795 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4722 - accuracy: 0.7795 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4721 - accuracy: 0.7795 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4720 - accuracy: 0.7795 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4719 - accuracy: 0.7795 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4715 - accuracy: 0.7795 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.7344\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4695 - accuracy: 0.7795 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4694 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4679 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4675 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4674 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4670 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4668 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4667 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4661 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4640 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4592 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4572 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4571 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4568 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4568 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4567 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4564 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4544 - accuracy: 0.7795 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.4544 - accuracy: 0.7795 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4543 - accuracy: 0.7795 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4543 - accuracy: 0.7795 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4540 - accuracy: 0.7795 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4540 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4539 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4539 - accuracy: 0.7795 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4538 - accuracy: 0.7795 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4536 - accuracy: 0.7795 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4532 - accuracy: 0.7795 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4532 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4530 - accuracy: 0.7812 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4528 - accuracy: 0.7795 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4508 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4505 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4502 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4501 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4498 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4495 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4494 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4494 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4493 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4492 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4492 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4491 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4488 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4487 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4487 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4486 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4480 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4480 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4479 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4478 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4478 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4470 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4462 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4460 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4458 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4456 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4453 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4452 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4452 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4450 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4449 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4448 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4448 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4446 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4445 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4445 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4444 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4443 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4421 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4419 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4418 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4417 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4417 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4416 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4412 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4395 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4394 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4390 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4390 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4390 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4368 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4359 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4354 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4351 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4351 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4346 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4345 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4345 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1008/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4345 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4345 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4344 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4337 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4333 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4333 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4333 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4332 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4332 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4332 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4332 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4331 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4331 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4330 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4330 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4330 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4329 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4330 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4329 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4329 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4328 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4327 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4327 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4327 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4327 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1063/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4326 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4327 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4326 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4326 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4325 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4325 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4326 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4324 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4324 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4324 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4323 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4324 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4323 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4322 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4323 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4323 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4322 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4321 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4321 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4321 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4321 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4321 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4320 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4321 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4320 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4321 - accuracy: 0.8038 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4320 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4320 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4318 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4319 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4318 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4317 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4318 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4317 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4317 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4316 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4316 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4316 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4315 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4316 - accuracy: 0.8038 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4315 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4315 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4314 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4315 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4314 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4314 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4314 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4314 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4314 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4313 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4313 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4312 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1118/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 42us/step - loss: 0.4313 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4312 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4312 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4311 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4311 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4311 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4311 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4312 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4310 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4311 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4310 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4310 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4310 - accuracy: 0.8056 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4309 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4309 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4308 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4308 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4308 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4308 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4308 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4308 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4307 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4308 - accuracy: 0.8056 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4307 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4306 - accuracy: 0.8056 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4306 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4305 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4305 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4304 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4304 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4304 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4304 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4304 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4304 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4303 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4303 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4303 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4303 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4302 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4302 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4302 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4302 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4301 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4300 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4300 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4300 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4299 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4300 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4300 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4299 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4299 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4299 - accuracy: 0.8108 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4299 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4298 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4298 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4298 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4298 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4296 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4296 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4298 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4296 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4296 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4296 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4295 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4295 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4295 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4294 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4293 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4293 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4293 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4293 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4293 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4292 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4293 - accuracy: 0.8108 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4292 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4293 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4291 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4291 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4291 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4291 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4291 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4291 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4290 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4290 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4290 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4289 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4289 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4290 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4289 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4288 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4288 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.4288 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4288 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4288 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4289 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4287 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4287 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4287 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4287 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4287 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4286 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4286 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4286 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4287 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4285 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4285 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4285 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4285 - accuracy: 0.8038 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4285 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4285 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4284 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4284 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4284 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4284 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4283 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4283 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4283 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4283 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4283 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4282 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4283 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4282 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4282 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4282 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4281 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4281 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4281 - accuracy: 0.8038 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4280 - accuracy: 0.8038 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4281 - accuracy: 0.8038 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4280 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4281 - accuracy: 0.8056 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4281 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4280 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4280 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4280 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4279 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4279 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4280 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4279 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4279 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4278 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4278 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1283/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 39us/step - loss: 0.4278 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4277 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4278 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4279 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4278 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4277 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4277 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4277 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4277 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4276 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4276 - accuracy: 0.8073 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4276 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4275 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4275 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4274 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4275 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4274 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4273 - accuracy: 0.8056 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4273 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4273 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4273 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4274 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4273 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4273 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4271 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4270 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4271 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1338/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4262 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1393/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4254 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4249 - accuracy: 0.8056 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4248 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1448/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 47us/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4243 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4242 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4237 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4237 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4237 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4237 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4236 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4237 - accuracy: 0.8038 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4236 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4236 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4237 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4236 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4235 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4235 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4234 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4234 - accuracy: 0.8056 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4234 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4234 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer=SGD(lr = .003),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.755\n",
      "roc-auc is 0.817\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
